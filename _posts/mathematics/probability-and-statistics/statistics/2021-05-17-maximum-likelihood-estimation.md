---
title: "Maximum Likelihood Estimation"
layout: post
use_math: true
tags: ["Statistics"]
---


2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í™•ë¥ ê³¼ í†µê³„' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- Introduction
- MLE; Maximum Likelihood Estimation
  - MLE for Bernoulli case
  - MLE for Normal case

<hr/>

### Introduction

\<MLE; Maximum Likelihood Estimation\>ì€ ì§€ê¸ˆê¹Œì§€ì˜ ì ‘ê·¼ë²•ê³¼ëŠ” ì‚¬ë­‡ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì´ë‹¤. \<MLE\>ëŠ” statistical inferenceë¥¼ ìˆ˜í–‰í•˜ëŠ” ë§ì€ ì ‘ê·¼ë²• ì¤‘ í•˜ë‚˜ë¡œ, statistical apporachì— ìƒˆë¡œìš´ ì² í•™ê³¼ ì‹œì•¼ë¥¼ ì œê³µí•œë‹¤ ğŸ˜

<br/>

<span class="statement-title">Example.</span><br>

í™•ë¥  $p$ë¥¼ ì •í™•íˆ ì•Œì§€ ëª»í•˜ëŠ” p-coinì„ 10ë²ˆ ë˜ì§„ë‹¤ê³  í•˜ì. 10ë²ˆì˜ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

<div align="center" style="margin: 8px">

H H T H T T H H H T

</div>

ì•ì—ì„œ ë°°ìš´ \<proportion estimation\>ì˜ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´, $p$ëŠ” Point Estimator $\hat{p} = 6/10$ìœ¼ë¡œ ì¶”ì •ëœë‹¤.

<br/>

ì´ë²ˆì—ëŠ” \<MLE\>ì˜ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì! ë¨¼ì € 10ì˜ ë™ì „ ë˜ì§€ê¸°ê°€ ìœ„ì™€ ê°™ì´ ë‚˜ì˜¬ í™•ë¥ ì€ ì•„ë˜ì™€ ê°™ë‹¤.

$$
P(H, H, T, \dots, H, T) = p^6 q^4
$$

ìœ„ì˜ ì‹ì„ ë‹¤ì‹œ ì“°ë©´, $L(p) = p^6 (1-p)^4$ë¡œ, ë™ì „ì˜ í™•ë¥ ì´ $p$ì¼ ë•Œ "H H ... H T"ì˜ ê²°ê³¼ë¥¼ ì–»ì„ í™•ë¥ ì„ ì˜ë¯¸í•œë‹¤.

ì´ì œ, ì´ í•¨ìˆ˜ $L(p)$ë¥¼ maximize í•˜ëŠ” $p$ë¥¼ êµ¬í•´ë³´ì. ë°©ë²•ì€ ê°„ë‹¨í•˜ë‹¤. ê·¸ëƒ¥ $p$ì— ëŒ€í•´ ë¯¸ë¶„ë°©ì •ì‹ì„ í’€ë©´ ëœë‹¤. ì´ë•Œ, ê³„ì‚°ì˜ í¸ì˜ë¥¼ ìœ„í•´ $\log$ë¥¼ ë¨¼ì € ì·¨í•´ì£¼ì.

$$
\ell(p) = \log (L(p)) = 6 \log p + 4 \log (1-p)
$$

$$
\frac{d\ell(p)}{dp} = \frac{6}{p} - \frac{4}{1-p} = 0 \quad \rightarrow \quad p = 6/10
$$

ì¦‰, $p=6/10$ì´ "H H ... H T"ë¼ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¬ í™•ë¥ ì„ Maximizeí•˜ëŠ” í™•ë¥ ì´ë¼ëŠ” ë§ì´ë‹¤!

ì´ì œ \<MLE\>ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ì •ë¦¬í•´ ë‹¤ì‹œ ì‚´í´ë³´ì!

<hr/>

### MLE; Maximum Likelihood Estimation

<div class="theorem" markdown="1">

<span class="statement-title">Theorem.</span> MLE for Bernoulli case<br>

Let $X_1, \dots, X_n$ be a $\text{Ber}(p)$ Random Samples, with iid.

Then, the likelihood function $L(p; x_1, \dots, x_n)$ would be

$$
\begin{aligned}
L(p;\, x_1, \dots, x_n)
&= f(x_1;\, p) \cdots f(x_n;\, p) \\
&= p^{x_1} (1-p)^{1-x_1} \cdots p^{x_n} (1-p)^{1-x_n} \\
&= p^{\sum x_i} (1-p)^{n - \sum x_i}
\end{aligned}
$$

Take log on it!

$$
\begin{aligned}
\ell(p) = \sum x_i \cdot \log p + (n - \sum x_i) \cdot \log (1-p)
\end{aligned}
$$

Take derivative for $p$!

$$
\frac{d\ell(p)}{dp} = \frac{\sum x_i}{p} - \frac{n-\sum x_i}{1-p} = 0
$$

when solve the equation, then

$$
p = \frac{\sum x_i}{n} = \bar{x}
$$

</div>

<hr/>

<div class="theorem" markdown="1">

<span class="statement-title">Theorem.</span> MLE for Normal case<br>

Let $X_1, \dots, X_n$ be a $N(\mu, 1)$ Random Samples, with iid.

Find the MLE of $\mu$!

$$
\begin{aligned}
L(\mu; \, x_1, \dots, x_n)
&= f(x_1; \, \mu) \cdots f(x_n; \, \mu) \\
&= \left( \frac{1}{\sqrt{2\pi}}\right)^n \exp \left( - \sum \, (x_i - \mu)^2 / \, 2 \right)
\end{aligned}
$$

Take log on it!

$$
\ell(\mu; \, \cdots) = n \cdot \log \left( \frac{1}{\sqrt{2\pi}}\right) - \frac{\sum \, (x_i - \mu)^2}{2}
$$

Take derivative for $\mu$!

$$
\frac{d\ell}{d\mu} = \sum (x_i - \mu) = 0
$$

when solve the equation, then

$$
\mu = \bar{x}
$$

</div>

<hr/>

ì´ì œ ë‹¤ìŒ í¬ìŠ¤íŠ¸ë¶€í„° í†µê³„í•™ì˜ ê½ƒğŸŒ¹ì´ë¼ê³  í•  ìˆ˜ ìˆëŠ” \<**ê°€ì„¤ ê²€ì •; Hypothesis Tests**\>ì— ëŒ€í•´ ë‹¤ë£¬ë‹¤!! ğŸ˜ ìš°ë¦¬ê°€ ì§€ê¸ˆê¹Œì§€ ìˆ˜í–‰í•œ "ì¶”ì •(Estimation)"ì„ í™œìš©í•´ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ ë°”ë¡œ \<Hypothesis Test\>ë‹¤!

ğŸ‘‰ [Introduction to Hypothesis Tests]({{"/2021/05/18/introduction-to-hypothesis-tests.html" | relative_url}})

