---
title: "Statistics - PS1"
toc: true
toc_sticky: true
categories: ["Statistics", "Problem Solving"]
---

â€œí™•ë¥ ê³¼ í†µê³„(MATH230)â€ ìˆ˜ì—…ì—ì„œ ë°°ìš´ ê²ƒê³¼ ê³µë¶€í•œ ê²ƒì„ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì „ì²´ í¬ìŠ¤íŠ¸ëŠ” [Probability and Statistics]({{"/category/probability-and-statistics" | relative_url}})ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ²

ì´ ê¸€ì€ "[Point Estimation]({{"/2021/05/05/point-estimation.html" | relative_url}})" í¬ìŠ¤íŠ¸ì—ì„œ ì œì‹œí•œ ìˆ™ì œ ë¬¸ì œë“¤ì„ í’€ì´í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

<span class="statement-title">TOC.</span><br>

- [MSE(Mean Squared Error) is the sum of variance and square of bias](#mse-is-the-sum-of-variance-and-square-of-bias)
- [Sample ariance $S^2$ is not the minimal variance estimator](#sample-variance-is-note-the-minimal-variance-estimator)
- [Compare $S^2$ and $\hat{S}^2$ which one is the most efficient variance estimator?](#which-one-is-the-most-efficient-variance-estimator)

<hr/>

## MSE is the sum of variance and square of bias

<div class="statement" markdown="1">

<span class="statement-title">Theorem.</span><br>

The \<MSE; Mean Squared Error\> of an estimator is defined as

$$
\text{MSE} := E \left[ \left( \hat{\Theta} - \theta \right)^2 \right] = \text{Var}(\hat{\Theta}) + \left[ \text{Bias} \right]^2
$$

where $\text{Bias} := E [ \hat{\Theta} - \theta ]$.

</div>

<div class="proof" markdown="1">

<span class="statement-title">*Proof*.</span><br>

ë¨¼ì €, MSE(Mean Square Error)ëŠ” ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.

$$
\text{MSE} = E [(\hat{\Theta} - \theta)^2]
$$

ìœ„ì˜ ì‹ì„ ë³€í˜•í•˜ë©´ ì•„ë˜ì™€ ê°™ê³ , ì´ë¥¼ ì „ê°œí•´ë³´ì.

$$
\begin{aligned}
E [(\hat{\Theta} - \theta)^2]
&= E \left[ (\hat{\Theta} - E[\hat{\Theta}] + E[\hat{\Theta}] - \theta)^2 \right] \\
&= E \left[ \left((\hat{\Theta} - E[\hat{\Theta}]) + (E[\hat{\Theta}] - \theta)\right)^2 \right] \\
&= E \left[ \cancelto{\text{Var}(\hat{\Theta})}{(\hat{\Theta} - E[\hat{\Theta}])^2} + (\hat{\Theta} - E[\hat{\Theta}]) (E[\hat{\Theta}] - \theta) + (E[\hat{\Theta}] - \theta)^2 \right] \\
&= \text{Var}(\hat{\Theta}) + E \left[ (\hat{\Theta} - E[\hat{\Theta}]) (E[\hat{\Theta}] - \theta) + (E[\hat{\Theta}] - \theta)^2 \right] \\
&= \text{Var}(\hat{\Theta}) + E \left[ \hat{\Theta} E[\hat{\Theta}] - \cancel{E[\hat{\Theta}]^2} - \hat{\Theta} \theta + \theta E [\hat{\Theta}] + \cancel{E[\hat{\Theta}]^2} + 2 \theta E[\hat{\Theta}] + \theta^2\right] \\
&= \text{Var}(\hat{\Theta}) + E \left[ \hat{\Theta} E[\hat{\Theta}] - \hat{\Theta} \theta - \theta E[\hat{\Theta}] + \theta^2\right]
\end{aligned}
$$

ìœ„ì˜ ì‹ì˜ ì˜¤ë¥¸í¸ì˜ í…€ì„ ì•„ë˜ì™€ ê°™ì´ ë¬¶ì–´ì¤€ë‹¤.

$$
\begin{aligned}
E \left[ \hat{\Theta} E[\hat{\Theta}] - \hat{\Theta} \theta - \theta E[\hat{\Theta}] + \theta^2\right]
&= E \left[ (\hat{\Theta} - \theta) E[\hat{\Theta}] - (\hat{\Theta} - \theta )\theta\right] \\
&= E \left[ (\hat{\Theta} - \theta) (E[\hat{\Theta}] - \theta)\right] \\
&= E \left[ (\hat{\Theta} - \theta) \cdot \cancelto{\text{bias}}{E[\hat{\Theta} - \theta]}\right] \\
&= \text{bias} \cdot \cancelto{\text{bias}}{E \left[ \hat{\Theta} - \theta \right]} \\
&= \text{bias} \cdot \text{bias} = (\text{bias})^2
\end{aligned}
$$

ë”°ë¼ì„œ, MSEëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

$$
\text{MSE} = \text{Var}(\hat{\Theta}) + (\text{bias})^2
$$

$\blacksquare$

</div>

<hr/>


## Sample Variance is not the minimal variance estimator

<div class="statement" markdown="1">

<span class="statement-title">Exercise.</span><br>

Let $X_1, \dots, X_n$ be iid $N(\mu, \sigma^2)$.

Let $\displaystyle S^2 := \frac{1}{n-1} \sum^n_i (X_i - \bar{X})^2$ and $\displaystyle \hat{S}^2 := \frac{1}{n} \sum^n_i (X_i - \bar{X})^2$

Show that $\text{Var}(S^2) > \text{Var}(\hat{S}^2)$.

</div>

<div class="proof" markdown="1">

<span class="statement-title">Solve.</span><br>

ë‘ estimatorì˜ Varianceë¥¼ êµ¬í•´ë³´ì.

$S^2$ì— ëŒ€í•´ $\dfrac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$ê°€ ì„±ë¦½í•˜ë¯€ë¡œ, ì•„ë˜ì˜ $\chi^2$ ë¶„í¬ì˜ ì„±ì§ˆì— ë”°ë¼ ì•„ë˜ì˜ ì‹ì´ ì„±ë¦½í•œë‹¤.

$$
\text{Var} \left(\frac{(n-1)S^2}{\sigma^2}\right) = \text{Var} \left(\chi^2(n-1)\right) = 2(n-1)
$$

ìœ„ì˜ ì‹ì„ ì˜ ì •ë¦¬í•˜ë©´,

$$
\begin{aligned}
\text{Var} \left(\frac{(n-1)S^2}{\sigma^2}\right)
&= 2(n-1) \\
\frac{(n-1)^2}{\sigma^4} \text{Var} (S^2)
&= 2(n-1) \\
\text{Var} (S^2)
&= \frac{2\sigma^4}{(n-1)}
\end{aligned}
$$

ì´ì œ, $\hat{S}^2$ì˜ Varianceë¥¼ êµ¬í•´ë³´ì.

$$
\begin{aligned}
\text{Var}(\hat{S}^2)
&= \text{Var} \left(\frac{n-1}{n}S^2\right) \\
&= \frac{(n-1)^2}{n^2}\text{Var}(S^2) \\
&= \frac{(n-1)^2}{n^2} \cdot \frac{2\sigma^4}{(n-1)} \\
&= \frac{2(n-1)\sigma^4}{n^2}
\end{aligned}
$$

ë‘ estimatorì˜ Varianceë¥¼ ë¹„êµí•´ë³´ë©´,

$$
\text{Var}(\hat{S}^2) = \frac{(n-1)^2}{n^2}\text{Var}(S^2) < \text{Var}(S^2)
$$

ì´ë‹¤. ì¦‰, $S^2$ ë³´ë‹¤ ë‚®ì€ varianceë¥¼ ê°–ëŠ” estimatorê°€ ì¡´ì¬í•œë‹¤. $\blacksquare$ <br/>
(ë‹¨, $\hat{S}^2$ëŠ” biased estimatorì„!)

</div>

<hr/>


## Which one is the most efficient variance estimator?

<div class="statement" markdown="1">

<span class="statement-title">Exercise.</span><br>

Compare $S^2$ and $\hat{S}^2$, which one is the most efficient estimator?

</div>

<div class="proof" markdown="1">

First, we know that the $S^2$ is an unbiased estimator, so $\text{bias}(S^2) = 0$.

Next, let's find the bias of $\hat{S}^2$.

$$
\begin{aligned}
\text{bias}(\hat{S}^2)
&= E \left[ \hat{S}^2 - \sigma^2 \right] \\
&= E \left[ \frac{1}{n} \sum_i^n (X_i - \bar{X})^2 - \sigma^2 \right] \\
&= E \left[ \frac{n-1}{n} \cdot \frac{1}{n-1} \sum_i^n (X_i - \bar{X})^2 - \sigma^2 \right] \\
&= \frac{n-1}{n} \cdot E \left[ \frac{1}{n-1} \sum_i^n (X_i - \bar{X})^2 \right] - \sigma^2 \\
&= \frac{n-1}{n} \cdot \sigma^2 - \sigma^2 \\
&= \frac{1}{n} \cdot \left( (n-1) \sigma^2 - n \sigma^2 \right) = - \frac{\sigma^2}{n}
\end{aligned}
$$

We've already got the variance of two estimators. Then, the MSE for two estimators are:

$$
\text{MSE}(S^2) = \frac{2\sigma^4}{(n-1)} + 0
$$

$$
\text{MSE}(\hat{S}^2) = \frac{2(n-1)\sigma^4}{n^2} + \frac{\sigma^4}{n^2}
$$

$$
\begin{aligned}
\frac{2\sigma^4}{(n-1)} \quad &\text{vs.} \quad \frac{2(n-1)\sigma^4}{n^2} + \frac{\sigma^4}{n^2} \\
\frac{2}{(n-1)} \quad &\text{vs.} \quad \frac{2(n-1)}{n^2} + \frac{1}{n^2} \\
\frac{2}{(n-1)} \quad &\text{vs.} \quad \frac{2(n-1) + 1}{n^2} \\
\frac{2}{(n-1)} \quad &\text{vs.} \quad \frac{2n-1}{n^2} \\
2 \cdot n^2 \quad &\text{vs.} \quad (2n-1) \cdot (n-1) \\
2 n^2 \quad &\text{vs.} \quad 2n^2 - 3n + 1 \\
\end{aligned}
$$

ì¦‰, $\text{MSE}(S^2) > \text{MSE}(\hat{S}^2)$ì´ë¯€ë¡œ, $\hat{S}^2$ê°€ "the most efficient estimator"ì´ë‹¤! $\blacksquare$

</div>