---
title: "Transformations of Random Variable - 1"
toc: true
toc_sticky: true
categories: ["Probability"]
---

â€œí™•ë¥ ê³¼ í†µê³„(MATH230)â€ ìˆ˜ì—…ì—ì„œ ë°°ìš´ ê²ƒê³¼ ê³µë¶€í•œ ê²ƒì„ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì „ì²´ í¬ìŠ¤íŠ¸ëŠ” [Probability and Statistics](https://bluehorn07.github.io/categories/probability-and-statistics)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ²
{: .notice--info}

ì´ë²ˆ ì±•í„° "Ch07. Functions of Random Variables"ì—ì„œëŠ” RV $X$ì— ì–´ë–¤ í•¨ìˆ˜ $f(x)$ë¥¼ ì”Œì›Œ $Y = f(X)$ë¼ëŠ” ìƒˆë¡œìš´ RVë¥¼ ë§Œë“¤ë•Œ, ì´ RV $Y$ì— ëŒ€í•œ ë¶„í¬ë¥¼ ì‚´í´ë³¸ë‹¤. ì¦‰, $f(X)$ì— ëŒ€í•œ pdf, cdfë¥¼ êµ¬í•œë‹¤ëŠ” ë§ì´ë‹¤.

ì‰¬ìš´ ê²½ìš°ë¶€í„° ì¡°ê¸ˆ ë³µì¡í•œ ê²½ìš°ê¹Œì§€ ìˆœì„œëŒ€ë¡œ ì‚´í´ë³¼ ê²ƒì´ë©°, $f(x)$ê°€ 1-1 functionì¼ ë•Œ, $f(x)$ê°€ not 1-1ì¼ ë•Œë¥¼ ì‚´í´ë³¸ë‹¤. ë’·ë¶€ë¶„ì—ì„œëŠ” RVì˜ momemtumì„ ì‰½ê²Œ êµ¬í•˜ëŠ” ë„êµ¬ì¸ \<MGF; Momentum Generating Function\> $M_X(t)$ì— ëŒ€í•´ ì‚´í´ë³¸ë‹¤.

<hr/>

## 1-1 Transformation

### Discrete Case

<span class="statement-title">Example.</span><br>

Let $X$ be a RV with $P(X = \pm 1) = 1/2$.

Let $Y = 3X - 5$, find the pmf of $Y$.

$$
P(Y = y) = \begin{cases}
    1/2 & y=-2 \\
    1/2 & y=-8 \\
    \; 0 & \text{else}
\end{cases}
$$

ìœ„ì˜ ê³¼ì •ì„ ì¢€ë” í’€ì–´ì„œ ì‚´í´ë³´ì. ê·¸ëŸ¬ë©´,

$$
\begin{aligned}
P(Y = y) &= P(3X - 5 = y)\\
&= P(f(X) = y) \\
&= P(X = f^{-1}(y))
\end{aligned}
$$

ì¦‰, $f(X)$ì—ì„œ ì—­í•¨ìˆ˜ $f^{-1}$ë¥¼ ì´ìš©í•´ $X$ì˜ pmfë¡œë¶€í„° ì†ì‰½ê²Œ $Y$ì˜ pmfë¥¼ ìœ ë„í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤!

$$
P(Y = y) = P(X = f^{-1}(y))
$$

<br/>

<div class="theorem" markdown="1">

<span class="statement-title">Theorem.</span> Discrete Case<br>

1\. Supp. $X$ has pmf $f_X (x)$.

Let $Y=g(X)$ where $g$ is 1-1 function with the inverse $x = g^{-1}(y)$.

Then,

$$
f_Y (y) = f_X (g^{-1}(y))
$$

<br/>

2\. Supp. $(X_1, X_2)$ has joint pmf $f_{X_1, X_2} (x_1, x_2)$.

Let $Y_1 := u_1 (X_1, X_2)$ and $Y_2 := u_2 (X_1, X_2)$, and $X_1 := w_1(Y_1, Y_2)$ and $X_2 := w_2 (Y_1, Y_2)$.

Then,

$$
f_{Y_1, Y_2} (y_1, y_2) = f_{X_1, X_2} \left( w_1(y_1, y_2), w_2(y_1, y_2) \right)
$$

</div>

ì¦‰, $X_1$, $X_2$ë¥¼ ì´ìš©í•´ $Y_1$, $Y_2$ë¥¼ ì •ì˜í•œ ì‹ì„ ì˜ í’€ì–´ì„œ, $Y_1$, $Y_2$ë¥¼ ì´ìš©í•´ $X_1$, $X_2$ë¥¼ ê¸°ìˆ í•œ ì‹ $w_1$, $w_2$ë¥¼ ì •ì˜í•˜ê³ , ê·¸ê²ƒìœ¼ë¡œ pmfë¥¼ ìœ ë„í•œë‹¤ëŠ” ë§ì´ë‹¤! ë‹¹ì—°í•œ ì ‘ê·¼ì„ ìˆ˜ì‹ìœ¼ë¡œ formalí•˜ê²Œ ê¸°ìˆ í•œ ê²ƒ ì •ë„ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.

<br/>

<span class="statement-title">Example.</span><br>

Let $X \sim \text{Poi}(\lambda)$ and $Y \sim \text{Poi}(\mu)$, and $X \perp Y$.

Find the distribution of $X + Y$.

<div class="math-statement" markdown="1">

ë§Œì•½ $P(X+Y = 5)$ë¼ê³  í•œë‹¤ë©´, ì´ê²ƒì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ $P(X = 0, Y=5)$, $P(X=1, Y=4)$, ..., $P(X=5, Y=0)$ì˜ í™•ë¥ ì„ êµ¬í•´ì„œ ë”í•  ê²ƒì´ë‹¤. ì´ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ì‹ì„ ì „ê°œí•´ë³´ì!

$$
\begin{aligned}
P(X+Y = n) &= \sum^{\infty}_{k=0} P(X=n-k, Y = k) \\
           &= \sum^{\infty}_{k=0} P(X=n-k) P(Y = k) \quad (\text{independence}) \\
           &= \sum^{\infty}_{k=0}  e^{-\lambda} \frac{\lambda^{n-k}}{(n-k)!} \cdot e^{-\mu} \frac{\mu^k}{k!} \\
           &= \frac{e^{-(\lambda + \mu)}}{n!} \sum^{\infty}_{k=0} \frac{n!}{(n-k)!k!} \lambda^{n-k} \mu^k \\
           &= \frac{e^{-(\lambda + \mu)}}{n!} \cdot (\lambda + \mu)^n = e^{-(\lambda + \mu)} \frac{(\lambda + \mu)^n}{n!}
\end{aligned}
$$

ì¦‰, $P(X+Y = n)$ëŠ” $\text{Poi}(\lambda+\mu)$ì˜ pmfë¼ëŠ” ê²ƒì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤! $\blacksquare$

</div>

<div class="math-statement" markdown="1">

We first find the joint pmf of $(X, X+Y)$, and then find the marginal pmf of $X+Y$.

Let $U = X$, $V = X+Y$, then $X = U$, $Y = V - U$.

ë”°ë¼ì„œ, $U$, $V$ì— ëŒ€í•œ pmfëŠ”

$$
\begin{aligned}
f_{U, V} (u, v) &= f_{X, Y} (u, v-u) \\
                &= f_X (u) f_Y(v-u) \quad (\text{independence}) \\
                &= e^{-\lambda} \frac{\lambda^u}{u!} \cdot e^{-\mu} \frac{\mu^{v-u}}{(v-u)!} \\
                &= e^{-(\lambda + \mu)} \frac{\lambda^u}{u!} \frac{\mu^{v-u}}{(v-u)!}
\end{aligned}
$$

$U$, $V$ì— ëŒ€í•œ joint pmfë¥¼ êµ¬í–ˆìœ¼ë‹ˆ, ì´ë²ˆì—ëŠ” $V$ì— ëŒ€í•œ marginal pmfë¥¼ êµ¬í•´ë³´ì.

$$
\begin{aligned}
f_V (v) &= \sum_u f_{U, V} (u, v) \\
        &= \sum_u e^{-(\lambda+\mu)} \frac{\lambda^u}{u!} \frac{\mu^{v-u}}{(v-u)!} \\
        &= e^{-(\lambda+\mu)} \sum_u \frac{\lambda^u}{u!} \frac{\mu^{v-u}}{(v-u)!} \\
        &= \frac{e^{-(\lambda+\mu)}}{v!} \sum_u \frac{v!}{u!(v-u)!} \lambda^u \mu^{v-u} \\
        &= \frac{e^{-(\lambda+\mu)}}{v!} \cdot (\mu + \lambda)^v \\
        &= e^{-(\lambda+\mu)} \frac{(\mu + \lambda)^v}{v!}
\end{aligned}
$$

ì¦‰, $V = X+Y$ì— ëŒ€í•œ pmfëŠ” ê²°êµ­ $\text{Poi}(\lambda + \mu)$ì¸ ê²ƒì´ë‹¤! $\blacksquare$

</div>

<hr/>

### Continuous Case

<div class="theorem" markdown="1">

<span class="statement-title">Theorem.</span><br>

Let $X$ be a continuous RV with pdf $f_X (x)$.

Let $Y := g(X)$ wgere $g$ is 1-1 with inverse $x = h(y)$.

Then,

$$
f_Y (y) = f_X (h(y)) \cdot \left| h'(y) \right|
$$

ğŸ’¥ Continuousì˜ ê²½ìš°, $\left\| h'(y) \right\|$ í…€ì´ ê³±í•´ì§„ë‹¤ëŠ” ì‚¬ì‹¤ì— ì£¼ëª©í•˜ì! ğŸ”¥

</div>

<br/>

<span class="statement-title">Example.</span><br>

1\. Let $X \sim N(\mu, \sigma^2)$ and let $Y := \dfrac{X - \mu}{\sigma}$.

Then,

$$
\begin{aligned}
f_Y (y) &= f_X (h(y)) \cdot \left| h'(y) \right| \\
        &= \frac{1}{\sqrt{2\pi} \sigma} \cdot \exp \left({- \frac{(h(y)-\mu)^2}{2\sigma^2}}\right) \cdot \left| \sigma \right|\\
        &= \frac{1}{\sqrt{2\pi} \cancel{\sigma}} \cdot \exp \left( - \frac{(\cancel{\sigma} y + \cancel{\mu} - \cancel{\mu})^2}{2\cancel{\sigma^2}} \right) \cdot \cancel{\sigma} \\
        &= \frac{1}{\sqrt{2\pi}} \cdot \exp \left( - y^2 / 2\right)
\end{aligned}
$$

<hr/>

2\. Let $X \sim \text{Gamma}(\alpha, 1)$, and let $Y := \beta X$.

**Claim**: $Y \sim \text{Gamma}(\alpha, \beta)$

$$
y = \beta x \iff x = \frac{y}{\beta} = h(y)
$$

and

$$
f_X (x) = \frac{1}{\Gamma(\alpha)} x^{\alpha - 1} e^{-x}
$$

then,

$$
\begin{aligned}
f_Y (y) &= f_X (h(y)) \cdot \left| h'(y) \right| \\
        &= \frac{1}{\Gamma(\alpha)} h(y)^{\alpha - 1} e^{-h(y)} \cdot \left| \frac{1}{\beta} \right| \\
        &= \frac{1}{\Gamma(\alpha) \beta} \cdot \left( \frac{y}{\beta}\right)^{\alpha-1} e^{-y/\beta} \\
        &= \frac{1}{\Gamma(\alpha) \beta^{\alpha}} \cdot y^{\alpha-1} e^{-y/\beta}
\end{aligned}
$$

ë”°ë¼ì„œ, $X \sim \text{Gamma}(\alpha, 1)$ì—ì„œ $Y = \beta X$ì˜ transformationì„ ì·¨í•˜ë©´, $Y \sim \text{Gamma}(\alpha, \beta)$ì˜ ë¶„í¬ë¥¼ ì–»ëŠ”ë‹¤.

<br/>

<hr/>

3\. Let $\theta \sim \text{Unif}(-\pi/2, \pi/2)$, and let $X = \tan \theta$.

Find the pdf of $X$.

$$
h(x) = \arctan x \quad \text{and} \quad h'(x) = \frac{1}{1+x^2}
$$

ìœ„ì˜ ê·œì¹™ì— ë§ì¶° $X$ì˜ ë¶„í¬ë¥¼ ìœ ë„í•´ë³´ë©´,

$$
\begin{aligned}
f_X (x) &= f_\theta (h(x)) \cdot \left| h'(x) \right| \\
        &= \cancelto{\frac{1}{\pi}}{f_\theta (\arctan x)} \cdot \frac{1}{1+x^2} \quad (\text{Uniform distribution})\\
        &= \frac{1}{\pi} \frac{1}{1+x^2}
\end{aligned}
$$

ì°¸ê³ ë¡œ ìœ„ì™€ ê°™ì€ ë¶„í¬ë¥¼ \<Cauchy Distribution\>ë¼ê³  í•œë‹¤.

<br/>

<hr/>

<span class="statement-title">Theorem.</span><br>

Let $X$ be a RV with cdf $F_X (x)$ which is strictly increasing.

Let $U \sim \text{Unif}(0, 1)$ Then,

1\. $Y := F_X^{-1}(U)$ has the same distribution of $X$.

2\.$Z := F_X(X)$ has the same distribution of $U$.

ê°œì¸ì ìœ¼ë¡œ ëª…ì œì— ëŒ€í•´ ì˜ ì´í•´ê°€ ë˜ì§€ ì•Šì•„, ì¦ëª…ì„ ë¨¼ì € ì´í•´í–ˆë‹¤.

<br/>

<span class="statement-title">*Proof*.</span> 1 <br>

<div class="math-statement" markdown="1">

$$
\begin{aligned}
P(Y \le y) &= P(F_X^{-1} (U) \le y) \\
           &= P(U \le F_X (y)) \\
           &= F_X (y) \quad (\text{by cdf of unfiorm $U$})
\end{aligned}
$$

ë”°ë¼ì„œ, $Y = F_X^{-1}(U)$ëŠ” $X$ì˜ ë¶„í¬ë¥¼ ê°–ëŠ”ë‹¤. $\blacksquare$

</div>

<span class="statement-title">*Proof*.</span> 2 <br>

<div class="math-statement" markdown="1">

$$
\begin{aligned}
P(Z \le x) &= P(F_X(X) \le x) \\
           &= P(X \le F_X^{-1}(x)) \\
           &= F_x \left( F_X^{-1} (x) \right) = x
\end{aligned}
$$

ë”°ë¼ì„œ, $Z = F_X(X)$ëŠ” uniform distribution $U(0, 1)$ì„ ê°–ëŠ”ë‹¤. $\blacksquare$

</div>

<span class="statement-title">**Exmaple**.</span><br>

Let $X \sim \text{Exp}(\lambda)$, then cdf is $F_X(x) = 1 - e^{-\lambda x}$.

ê·¸ëŸ¬ë©´ ìš°ë¦¬ëŠ” $F_X^{-1}$ì™€ $U$ë¥¼ ì´ìš©í•´ $X$ì˜ ë¶„í¬ë¥¼ ê°–ëŠ” RVë¥¼ ìœ ë„í•  ìˆ˜ ìˆë‹¤!!

By above theorem,

$$
F_X^{-1}(U) = \frac{-\ln (1-U)}{\lambda} \sim X
$$

ë§ë¶™ì´ë©´, $U$ì—ì„œ $X$ë¡œ ê°€ëŠ” Transformationì„ ì°¾ê³  ì‹¶ì€ë°, ê·¸ê±¸ $F_X^{-1}$ë¡œ ì„¤ì •í•˜ë©´ ì•„ì£¼ ì‰½ê²Œ $U$ì—ì„œ $X$ë¡œ ê°€ëŠ” Transformì„ ì°¾ëŠ”ê²Œ ëœë‹¤ëŠ” ë§ì´ë‹¤!! ğŸ¤©

<hr/>

<div class="theorem" markdown="1">

<span class="statement-title">Theorem.</span> Continuous case - Two Random Variables<br>

Let $(X, Y) \mapsto \left( u(X, Y), v(X, Y) \right)$ with the inverse $(U, V) \mapsto \left(w_1(U, V), w_2(U, V)\right)$.

If $(X, Y)$ has joint pdf $f_{X, Y}(x, y)$, then $(U, V)$ has joint pdf

$$
f_{U, V} (u, v) = f_{X, Y} \left( w_1(U, V), w_2(U, V) \right) \cdot \left| J \right|
$$

where $J$ is *Jaccobian Matrix*

$$
J = \begin{pmatrix}
        \frac{\partial w_1}{\partial u} & \frac{\partial w_1}{\partial v} \\
        \frac{\partial w_2}{\partial u} & \frac{\partial w_2}{\partial v} \\
\end{pmatrix}
$$

ì°¸ê³ ë¡œ *Jaccobian* $J$ëŠ” ì ë¶„ ë³€ìˆ˜ë¥¼ ë°”ê¾¸ëŠ” ê³¼ì •ì—ì„œ ë“±ì¥í–ˆë‹¤.

$x = w_1(u, v)$, $y = w_2(u, v)$ë¼ê³  í•˜ê³ , ì ë¶„ ë³€ìˆ˜ë¥¼ $u$, $v$ë¡œ ë³€í™˜í•œë‹¤ë©´,

$$
\int \int_{X, Y} f(x, y) \, dxdy = \int \int_{U, V} f\left( w_1 (u, v), w_2(u, v) \right) \left| J \right| \, dudv
$$

ê·¸ë˜ì„œ ì˜ ì‚´í´ë³´ë©´, $(U, V)$ì— ëŒ€í•œ pdf $f_{U, V}(u, v)$ëŠ” ìœ„ì˜ ì‹ì˜ ìš°ë³€ì—ì„œ ì ë¶„ ë‚´ë¶€ì˜ í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¨ ê²ƒì„ì„ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆë‹¤!!

</div>

<br/>

<span class="statement-title">**Example**.</span> [1]<br>

Let $X \sim N(0, 1)$ and $Y \sim N(0, 1)$, and $X \perp Y$.

Let $U := X + Y$ and $V := X - Y$.

1\. Find the joint pdf of $(U, V)$

ë¨¼ì € $w_1(u, v)$, $w_2(u, v)$ë¥¼ êµ¬í•œë‹¤.

$$
\begin{aligned}
x &= \frac{u+v}{2} = w_1(u, v) \\
y &= \frac{u-v}{2} = w_2(u, v)
\end{aligned}
$$

ì´ê²ƒì„ ê·¸ëŒ€ë¡œ ì ìš©í•´ë³´ë©´,

$$
\begin{aligned}
f_{U, V}(u, v) &= f_{X, Y} \left( w_1(u, v), w_2(u, v) \right) \cdot
\cancelto{1/2}{\left| \begin{matrix}
  1/2 & 1/2 \\
  1/2 & -1/2
\end{matrix}\right|} \\
&= f_{X, Y} \left( \frac{u+v}{2}, \frac{u-v}{2} \right) \frac{1}{2} \\
&= f_X \left( \frac{u+v}{2} \right) f_Y \left(\frac{u-v}{2}\right) \frac{1}{2} \qquad (X \perp Y) \\
&= \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{(u+v)^2}{8} \right) \cdot \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{(u-v)^2}{8} \right) \cdot \frac{1}{2} \\
&= \frac{1}{4\pi} \exp \left( - \frac{u^2 + v^2}{4}\right)
\end{aligned}
$$

<br/>

2\. Are $U$ and $V$ independent?

A. Yes!

$$
\begin{aligned}
f_{U, V} (u, v) &= \frac{1}{4\pi}  \exp \left( - \frac{u^2 + v^2}{4}\right) \\
\end{aligned}
$$

ìš°ë¦¬ëŠ” $f_{U, V} (u, v)$ì˜ ì‹ì—ì„œ $f_U (u)$ë¥¼ ìœ ë„í•´ë³´ë©´,

$$
\begin{aligned}
f_U(u) = \frac{1}{\sqrt{2\pi} \cdot (\sqrt{2})^2} \cdot \exp \left( - \frac{u^2}{2 \cdot (\sqrt{2})^2}\right)
\end{aligned}
$$

ì¦‰, $U$ëŠ” $N(0, (\sqrt{2})^2)$ì˜ ë¶„í¬ë¥¼ ê°€ì§ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤!

<br/>

3\. Let $Z := \dfrac{Y}{X}$. Find the pdf of $Z$.

Let $U := X$, and $V := \dfrac{Y}{X}$, then

$$
\begin{aligned}
X &= U \\
Y &= UV
\end{aligned}
$$

and *Jaccobian* is

$$
\left| J \right| = \left| \begin{matrix}
1 & 0 \\
\cdot & u
\end{matrix}\right| = \left| u \right|
$$

ì¬ë£ŒëŠ” ë‹¤ ê°–ì¶°ì¡Œìœ¼ë‹ˆ, ì´ì œ pdf $f_{U, V}(u, v)$ë¥¼ êµ¬í•´ë³´ì.

$$
\begin{aligned}
f_{U, V}(u, v) &= f_{X, Y} (u, uv) \cdot \left| u \right| \\
&= f_X (u) \cdot f_Y (uv) \cdot \left| u \right| \\
&= \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{u^2}{2} \right) \cdot \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{u^2v^2}{2}\right) \cdot \left| u \right| \\
&= \frac{1}{2\pi} \cdot \exp \left( - \frac{u^2(1+v^2)}{2}\right) \cdot \left| u \right|
\end{aligned}
$$

ì´ë•Œ, ìš°ë¦¬ê°€ ëª©í‘œë¡œ í•˜ëŠ” ë¶„í¬ì¸ $Z$, ì¦‰ $V := \dfrac{Y}{X}$ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ $f_{U, V}(u, v)$ì—ì„œ marginalize out í•´ì¤€ë‹¤.

$$
\begin{aligned}
f_Z (z) &= f_V (v) = \int f_{U, V} (u, v) \, du \\
&= \frac{1}{2\pi} \int^{\infty}_{-\infty} \left| u \right| \cdot \exp \left( - \frac{u^2(1+v^2)}{2}\right) \, du \\
&= \frac{1}{2\pi} \cdot 2 \int^{\infty}_0 \left| u \right| \cdot \exp \left( - \frac{u^2(1+v^2)}{2}\right) \, du \\
&= \frac{1}{2\pi} \cdot 2 \int^{\infty}_0 \frac{1}{2} \cdot \exp \left( - \frac{t(1+v^2)}{2}\right) \, dt \qquad (u^2 = t) \\
&= \frac{1}{2\pi} \cdot \left( \left. \frac{2}{-(1+v^2)} \cdot \exp \left( - \frac{t(1+v^2)}{2}\right) \right]^{\infty}_0 \right) \\
&= \frac{1}{2\pi} \cdot \frac{2}{-(1+v^2)} \left\{ 0 - 1\right\} \\
&= \frac{1}{\pi} \cdot \frac{1}{1+v^2}
\end{aligned}
$$

ì¦‰, ìœ„ì™€ ê°™ì´ $Z := \dfrac{Y}{X}$ì— ëŒ€í•œ ë¶„í¬ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤!! ì°¸ê³ ë¡œ ìœ„ì˜ ë¶„í¬ëŠ” ì•ì—ì„œ ì ê°„ ì–¸ê¸‰ëœ \<Cauchy Distribution\>ì´ë‹¤!

<br/>

<span class="statement-title">**Example**.</span> [2]<br>

Let $(X, Y)$ have the joint pdf

$$
f_{X, Y}(x, y) = \begin{cases}
  4xy & \text{for } 0 < x < 1 \text{ and } 0 < y < 1\\
  0 & \text{else}
\end{cases}
$$

1\. Find the joint pdf of $(X^2, XY)$.

$$
\begin{aligned}
U &= X^2 \\
V &= XY
\end{aligned}
$$

then, inverse relation is

$$
\begin{aligned}
x &= \sqrt{u} \\
y &= \frac{v}{\sqrt{u}} \\
0 < \sqrt{u} < 1 \quad &\text{and} \quad 0 < \frac{v}{\sqrt{u}} < 1
\end{aligned}
$$

and *Jaccobian* is

$$
\left| J \right| = \left|
\begin{matrix}
  \frac{1}{2\sqrt{u}} & 0 \\
  \cdot & \frac{1}{\sqrt{u}}
\end{matrix}
\right| = \frac{1}{2u}
$$

ë”°ë¼ì„œ, pdf $f_{U, V} (u, v)$ëŠ”

$$
\begin{aligned}
f_{U, V} (u, v) &= f_{X, Y} \left(\sqrt{u}, \frac{v}{\sqrt{u}}\right) \cdot \left| \frac{1}{2u} \right|\\
                &= 4 \cancel{\sqrt{u}} \frac{v}{\cancel{\sqrt{u}}} \cdot \frac{1}{2u} \\
                &= \frac{2v}{u} \qquad \text{for } 0 < u < 1 \text{ and } 0 < v < \sqrt{u}
\end{aligned}
$$

2\. Find the marginal pdf of $X^2$ and $XY$.

(1) $f_U(u) = f_{X^2}(u)$

$$
\begin{aligned}
f_{X^2} (u) &= \int^{\sqrt{u}}_0 \frac{2v}{u} \, dv \\
            &= \frac{1}{u} \cdot (\sqrt{u})^2 = 1
\end{aligned}
$$

ë”°ë¼ì„œ, $X^2$ì€ $\text{Unif}(0, 1)$ì˜ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤!

(2) $f_V(v) = f_{XY}(v)$

$$
\begin{aligned}
f_{XY}(v) &= \int^1_{v^2} \frac{2v}{u} \, du \\
          &= 2v \cdot \ln(1-v^2)
\end{aligned}
$$

<hr/>

ì´ì–´ì§€ëŠ” í¬ìŠ¤íŠ¸ì—ì„œëŠ” Random Variableì— ëŒ€í•œ Transformationì„ ì´ì–´ì„œ ì‚´í´ë³¸ë‹¤. 1-1ì´ ì•„ë‹Œ mappingì˜ ê²½ìš°ë¥¼ ì¢€ë” ì‚´í´ë³¼ ì˜ˆì •ì´ë‹¤.

ğŸ‘‰ [Transformations of Random Variable - 2]({{"/2021/04/12/transformations-of-random-variable-2" | relative_url}})