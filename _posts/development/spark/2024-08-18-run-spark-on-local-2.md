---
title: "ğŸ’» ë¡œì»¬ ë§¥ë¶ì—ì„œ Spark ì‹¤í–‰í•˜ê¸° - 2í¸: Client Mode"
toc: true
toc_sticky: true
categories: ["Spark"]
excerpt: "ë¡œì»¬ì—ì„œ Spark í´ëŸ¬ìŠ¤í„° êµ¬ì¶•í•˜ê¸° âœŒï¸ Master Nodeê°€ Cluster Managerê°€ ë˜ëŠ” Standalon ëª¨ë“œ. Spark Applicationì„ ì‹¤í–‰í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•: Client ëª¨ë“œ, Cluster ëª¨ë“œ. Master vs. Worker ê·¸ë¦¬ê³  Driver vs. Executor"
---

Databricks Certification ì·¨ë“ì„ ëª©í‘œë¡œ Apache Sparkë¥¼ â€œì œëŒ€ë¡œâ€ ê³µë¶€í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤. íšŒì‚¬ì—ì„  Databricks Unity Catalogë¥¼ ë„ì…í•˜ë ¤ê³  ë¶„íˆ¬í•˜ê³  ìˆëŠ”ë°ìš”. Sparkì™€ ì¢€ ì¹œí•´ì§ˆ ìˆ˜ ìˆì„ê¹Œìš”? ğŸ‡ ì „ì²´ í¬ìŠ¤íŠ¸ëŠ” [Development - Spark](/topic/development#apache-spark)ì—ì„œ í™•ì¸í•´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

1í¸ì—ì„œëŠ” ë‹¨ì¼ ë¨¸ì‹ ì—ì„œ ì‹¤í–‰í•˜ëŠ” "Local Mode"ë¡œ Spark ì‘ì—…ì„ í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì•˜ë‹¤. 2í¸ì—ì„œëŠ” "Client Mode"ë¡œ Spark í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê³ , Spark ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì.

# Setup Spark Cluster

## Setup Master Node

ë¨¼ì € Master ë…¸ë“œë¥¼ ë„ì›Œë³´ì. `pyspark`ë¡œ Sparkë¥¼ ì„¸íŒ…í–ˆë‹¤ë©´, í•¨ê»˜ ì œê³µí•˜ëŠ” `spark-class` ëª…ë ¹ì–´ë¡œ Master ë…¸ë“œë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.

```sh
$ spark-class org.apache.spark.deploy.master.Master -h localhost
...
24/08/22 00:52:41 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
24/08/22 00:52:41 INFO Master: Starting Spark master at spark://localhost:7077
24/08/22 00:52:41 INFO Master: Running Spark version 3.5.2
24/08/22 00:52:41 INFO JettyUtils: Start Jetty 0.0.0.0:8080 for MasterUI
24/08/22 00:52:41 INFO Utils: Successfully started service 'MasterUI' on port 8080.
24/08/22 00:52:41 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://172.30.1.16:8080
24/08/22 00:52:41 INFO Master: I have been elected leader! New state: ALIVE
```

ê·¸ë¦¬ê³  `http://localhost:8080`ì— ì ‘ì†í•˜ë©´, Spark UIë„ ë³¼ ìˆ˜ ìˆë‹¤.

![](/images/development/spark/spark-master-deploy.png){: .align-center style="max-height: 480px" }
Master ë…¸ë“œë§Œ ë„ìš´ ìƒíƒœ
{: .align-caption .text-center .small .gray }

ì¼ë‹¨ Master ë…¸ë“œë§Œ ë„ìš´ ìƒíƒœì—ì„œ ìš”ê¸°ì— `spark-hello.py` ì‘ì—…ì„ `spark-submit` í•´ë³´ì.

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  ./hello-spark.py
```

ì´ ìƒíƒœì—ì„  Spark Applicationì€ ë§Œë“¤ì–´ì§„ë‹¤. ê·¸ëŸ¬ë‚˜ Spark Appì„ ì‹¤í–‰í•  ì›Œì»¤ê°€ ì—†ê¸° ë•Œë¬¸ì—, ì‹¤í–‰ì´ ë˜ì§€ ì•Šê³  ê³„ì† ê¸°ë‹¤ë¦¬ê¸°ë§Œ í•œë‹¤.

> WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

ì¦‰, Workerê°€ ì•„ì§ ë¶™ì§€ ì•Šì•„ì„œ Spark Appì´ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆì—ˆë‹¤! ê·¸ëŸ¬ë©´ ì´ì œ ì›Œì»¤ ë…¸ë“œë¥¼ ë¶™ì—¬ë³´ì.

## Setup Worker Node

```bash
$ spark-class org.apache.spark.deploy.worker.Worker \
    spark://localhost:7077
---
...
24/08/22 13:00:57 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/08/22 13:00:57 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/08/22 13:00:57 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://172.16.80.54:8081
24/08/22 13:00:57 INFO Worker: Connecting to master localhost:7077...
24/08/22 13:00:57 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:7077 after 11 ms (0 ms spent in bootstraps)
24/08/22 13:00:57 INFO Worker: Successfully registered with master spark://localhost:7077
```

![](/images/development/spark/spark-cluster-deploy.png){: .align-center style="max-height: 400px" }
Master ë…¸ë“œì— Worker ë…¸ë“œë¥¼ í•˜ë‚˜ ë¶™ì¸ ìƒíƒœ
{: .align-caption .text-center .small .gray }

ì°¸ê³ ë¡œ Worker ë…¸ë“œ ìì²´ì˜ Spark UIë„ ìˆëŠ”ë°, ìš”ê±´ `http://localhost:8081`ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆë‹¤.

## spark-submit again

ì´ì œ Master ë…¸ë“œì™€ Worker ë…¸ë“œ ë‘˜ ë‹¤ êµ¬ì„±ì„ í–ˆìœ¼ë‹ˆ, ë‹¤ì‹œ `spark-submit`ì„ í•´ë³´ì.

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  ./hello-spark.py
```

![](/images/development/spark/spark-submit-on-cluster-mode.png){: .align-center style="max-height: 400px" }
`spark-submit`ì„ ì‹¤í–‰ í–ˆì„ ë•Œì˜ Master ë…¸ë“œì˜ Spark UI
{: .align-caption .text-center .small .gray }

Spark Appì´ ì‹¤í–‰ë˜ê³ , Completed ìƒíƒœë¡œ ë„˜ì–´ê°„ ê±¸ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  Worker ë…¸ë“œì—ì„œëŠ” ì´ë ‡ê²Œ ë‚˜ì˜¨ë‹¤.

![](/images/development/spark/spark-worker-view.png){: .align-center style="max-height: 400px" }
`spark-submit`ì„ ì‹¤í–‰ í–ˆì„ ë•Œì˜ Worker ë…¸ë“œì˜ Spark UI
{: .align-caption .text-center .small .gray }

<br/>

Spark UIë¥¼ í†µí•´ ì§€í‘œë¥¼ ì‚´í´ë³´ë©´, ê°„ë‹¨í•œ count ì‘ì–¸ì¸ë°ë„ CPU coreë¥¼ ë¬´ë ¤ `12 core`ë‚˜ ì‚¬ìš©í–ˆë‹¤! ì´ê²ƒì€ `spark-submit`ì„ í•  ë•Œ, ë”°ë¡œ ì‚¬ìš©í•  Coreì™€ Memory ìš©ëŸ‰ì„ ì§€ì •í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤!

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  --total-executor-cores 2 \
  --executor-memory 500m \
  ./hello-spark.py
```

![](/images/development/spark/spark-submit-with-custom-spec.png){: .align-center style="max-height: 400px" }
Core ìˆ˜ì™€ Memory ìˆ˜ë¥¼ ì¡°ì •í•´ `spark-submit`ì„ ì‹¤í–‰í•œ ëª¨ìŠµ
{: .align-caption .text-center .small .gray }

# Spark Standalone ëª¨ë“œ

Master-Worker ë…¸ë“œë¡œ Spark í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•œ ì´ ë°©ì‹ì„ "Standalone" ëª¨ë“œë¼ê³  í•œë‹¤.

ë³¸ë˜ Spark í´ëŸ¬ìŠ¤í„°ëŠ” Master ë…¸ë“œ, Worker ë…¸ë“œ ë¿ë§Œ ì•„ë‹ˆë¼ "Cluster Manager"ë¼ëŠ” ì»´í¬ë„ŒíŠ¸ê°€ ìˆì–´ Spark í´ëŸ¬ìŠ¤í„° ìƒíƒœ ê´€ë¦¬, ë¦¬ì†ŒìŠ¤ í• ë‹¹, ì‘ì—… ë¶„ë°° ë“±ì˜ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

- Memory Management
- Fault Recovery
- Task Scheduling

![](https://spark.apache.org/docs/latest/img/cluster-overview.png){: .align-center style="max-height: 400px" }

Standaloneì˜ ëœ»ì¸ "ìë¦½í˜•/ë…ë¦½í˜•"ë¼ëŠ” ëœ»ì— ë§ê²Œ Standalone ëª¨ë“œì—ì„œëŠ” Master ë…¸ë“œê°€ Cluster Managerì˜ ì—­í• ê¹Œì§€ ìˆ˜í–‰í•œë‹¤.

Spark í´ëŸ¬ìŠ¤í„°ë¥¼ Prod í™˜ê²½ì—ì„œ ìš´ì˜í•  ë•ŒëŠ” YARNì´ë‚˜ Mesosë¥¼ Cluster Managerë¡œ ë§ì´ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤.  spark-on-kubernetesë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ ìš´ì˜í•œë‹¤ë©´, Kubernetesê°€ Cluster Managerì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê¸°ë„ í•œë‹¤.

# Client Modeì— ëŒ€í•´ ì¢€ë” ìì„¸íˆ

![](/images/development/spark/spark-client-mode.png){: .align-center style="max-height: 400px" }
Spark Client Mode
{: .align-caption .text-center .small .gray }

ì§€ë‚œ í¬ìŠ¤íŠ¸ì—ì„œëŠ” "Local Mode"ë¡œ Spark Applicationì„ ì‹¤í–‰í–ˆë‹¤ë©´, ì´ë²ˆì—ëŠ” "Client Mode"ë¡œ Spark Appì„ ì‹¤í–‰í–ˆë‹¤. Client ëª¨ë“œì—ì„œëŠ” Driver Processê°€ Client JVM ìœ„ì—ì„œ ì‹¤í–‰ëœë‹¤. ê·¸ë¦¬ê³  Worker JVM ìœ„ì—ì„œ Executor Processë“¤ì´ ì‹¤í–‰ë˜ëŠ” êµ¬ì¡°ë‹¤.

## Master and Worker, Driver and Executor

ì´ ë¶€ë¶„ì„ ê³µë¶€í•˜ë©´ì„œ ì–´ë–¨ ë•ŒëŠ” Master-Worker ë˜ëŠ” Driver-Workerë¼ê³  ë¶€ë¥´ê³ , ë˜ ì–´ë–¨ ë•ŒëŠ” Driver-Executorë¼ê³  ë¶€ë¥´ëŠ” ìš©ì–´ë“¤ì´ ì •ë§ í—·ê°ˆë ¸ë‹¤.

ê·¸ë˜ì„œ ì°¾ì•„ë³´ë‹ˆ ì´ë ‡ê²Œ ì„¤ëª…í•˜ëŠ” ê³³ì´ ìˆì—ˆë‹¤.

- Spark í´ëŸ¬ìŠ¤í„° ê´€ì ì—ì„œëŠ”
  - Master ë…¸ë“œì™€ Worker ë…¸ë“œë¡œ êµ¬ì„±ëœë‹¤.
  - ê° ë…¸ë“œëŠ” ë¬¼ë¦¬ì  ë¨¸ì‹ ì˜ ê°œë…ì´ë‹¤.
- Sparkì˜ ê´€ì ì—ì„œëŠ”
  - Driver Processì™€ Executor Progressë¡œ êµ¬ì„±ëœë‹¤.
  - Process ëŒ€ì‹  Programë¼ê³ ë„ ë§í•œë‹¤.

ì´ë•Œ, Driver ProcessëŠ” ë°˜ë“œì‹œ Master ë…¸ë“œì— ëœ¨ëŠ” ê±´ ì•„ë‹ˆë‹¤. ì•ì—ì„œ ì‚´í´ë³¸ Client ModeëŠ” Driver Processê°€ Clientì˜ JVMì— ëœ¬ë‹¤. ë°˜ë©´ì—, ì•„ì§ ì‹¤í—˜í•´ë³´ì§€ ì•Šì€ "Cluster Mode"ì—ì„œëŠ” Driver Processê°€ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œ ê²°ì •ëœë‹¤. (ì´ê²ƒë„ Master ë…¸ë“œì— ë°˜ë“œì‹œ ëœ¨ëŠ”ê²Œ ì•„ë‹ˆë¼ Worker ë…¸ë“œ ì¤‘ í•˜ë‚˜ì— Driver Processê°€ ì‹¤í–‰ë˜ëŠ” ê²½ìš°ë„ ìˆë‹¤ëŠ” ê²ƒ ê°™ë‹¤. ğŸ˜µâ€ğŸ’«)


![](/images/development/spark/spark-cluster-mode.png){: .align-center style="max-height: 400px" }
Spark Cluster Mode
{: .align-caption .text-center .small .gray }

ìœ„ì˜ Client Modeì—ì„œì˜ ê·¸ë¦¼ê³¼ ì˜ ë¹„êµí•´ë³´ë©´, Client JVMì¸ì§€ Driver JVMì¸ì§€ í‘œê¸°ê°€ ë‹¤ë¥´ê²Œ ë˜ì–´ ìˆë‹¤. ì•„ë˜ëŠ” Spark ê³µì‹ ë¬¸ì„œì—ì„œ ë¬˜ì‚¬ëœ Client ëª¨ë“œì™€ Cluster ëª¨ë“œì˜ ì°¨ì´ì ì´ë‹¤.

> Spark Deploy Mode: Distinguishes where the driver process runs. In "cluster" mode, the framework launches the driver inside of the cluster. In "client" mode, the submitter launches the driver outside of the cluster. - [Spark Doc](https://spark.apache.org/docs/latest/cluster-overview.html#glossary)


# ë‹¤ìŒì—ëŠ”

ì•„ì§ "Cluster Mode"ë¥¼ ì œëŒ€ë¡œ ì‚´í´ë³´ì§€ ëª» í–ˆë‹¤. ì‹¤í—˜ì€ í•´ë´¤ëŠ”ë°, ì•„ë˜ì™€ ê°™ì€ ì˜¤ë¥˜ê°€ ëœ¨ë©´, Cluster Modeì—ì„œëŠ” `pyspark`ë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ì—†ë‹¤ê³  í•œë‹¤.

> Exception in thread "main" org.apache.spark.SparkException: Cluster deploy mode is currently **not supported** for python applications on standalone clusters.

ê·¸ë˜ì„œ Cluster ModeëŠ” ë‹¤ìŒì— scala ì‹¤í—˜ì„ í•˜ê²Œ ë  ë•Œ ë‹¤ì‹œ ì‚´í´ë³¼ ê²ƒ!

<br/>

ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„  `SparkSession`ê³¼ `SparkContext`ë¥¼ ì‚´í´ë³´ê³  ë‘˜ì„ ë¹„êµ í•´ë³´ê³ ì í•œë‹¤.

ğŸ‘‰ [Jump into Spark Sessions](/2024/08/21/jump-into-spark-sessions-and-contexts/)
