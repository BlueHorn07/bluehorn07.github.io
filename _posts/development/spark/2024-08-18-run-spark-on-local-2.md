---
title: "ğŸ’» ë¡œì»¬ ë§¥ë¶ì—ì„œ Spark ì‹¤í–‰í•˜ê¸° - 2í¸: Cluster Mode"
toc: true
toc_sticky: true
categories: ["Spark"]
excerpt: ""
---

2024ë…„ ëª©í‘œë¡œ Databricks Certificationì„ ì·¨ë“í•´ë³´ë ¤ê³  Apache Sparkë¥¼ "ì œëŒ€ë¡œ" ê³µë¶€í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤. ğŸ‡
{: .notice--info}

1í¸ì—ì„œëŠ” ë‹¨ì¼ ë¨¸ì‹ ì—ì„œ ì‹¤í–‰í•˜ëŠ” Local Modeë¡œ Spark ì‘ì—…ì„ í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì•˜ë‹¤. 2í¸ì—ì„œëŠ” Cluster Modeë¡œ Spark í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê³ , Spark ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì.

# Setup Spark Cluster

## Setup Master Node

ë¨¼ì € Master ë…¸ë“œë¥¼ ë„ì›Œë³´ì. `pyspark`ë¡œ Sparkë¥¼ ì„¸íŒ…í–ˆë‹¤ë©´, í•¨ê»˜ ì œê³µí•˜ëŠ” `spark-class` ëª…ë ¹ì–´ë¡œ Master ë…¸ë“œë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.

```sh
$ spark-class org.apache.spark.deploy.master.Master -h localhost
...
24/08/22 00:52:41 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
24/08/22 00:52:41 INFO Master: Starting Spark master at spark://localhost:7077
24/08/22 00:52:41 INFO Master: Running Spark version 3.5.2
24/08/22 00:52:41 INFO JettyUtils: Start Jetty 0.0.0.0:8080 for MasterUI
24/08/22 00:52:41 INFO Utils: Successfully started service 'MasterUI' on port 8080.
24/08/22 00:52:41 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://172.30.1.16:8080
24/08/22 00:52:41 INFO Master: I have been elected leader! New state: ALIVE
```

ê·¸ë¦¬ê³  `http://localhost:8080`ì— ì ‘ì†í•˜ë©´, Spark UIë„ ë³¼ ìˆ˜ ìˆë‹¤.

![](/images/development/spark/spark-master-deploy.png){: .align-center style="max-height: 480px" }
Master ë…¸ë“œë§Œ ë„ìš´ ìƒíƒœ
{: .align-caption .text-center .small .gray }

ì¼ë‹¨ Master ë…¸ë“œë§Œ ë„ìš´ ìƒíƒœì—ì„œ ìš”ê¸°ì— `spark-hello.py` ì‘ì—…ì„ `spark-submit` í•´ë³´ì.

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  ./hello-spark.py
```

ì´ ìƒíƒœì—ì„  Spark Applicationì€ ë§Œë“¤ì–´ì§„ë‹¤. ê·¸ëŸ¬ë‚˜ Spark Appì„ ì‹¤í–‰í•  ì›Œì»¤ê°€ ì—†ê¸° ë•Œë¬¸ì—, ì‹¤í–‰ì´ ë˜ì§€ ì•Šê³  ê³„ì† ê¸°ë‹¤ë¦¬ê¸°ë§Œ í•œë‹¤.

> WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources

ì¦‰, Workerê°€ ì•„ì§ ë¶™ì§€ ì•Šì•„ì„œ Spark Appì´ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆì—ˆë‹¤! ê·¸ëŸ¬ë©´ ì´ì œ ì›Œì»¤ ë…¸ë“œë¥¼ ë¶™ì—¬ë³´ì.

## Setup Worker Node

```bash
$ spark-class org.apache.spark.deploy.worker.Worker \
    spark://localhost:7077
---
...
24/08/22 13:00:57 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/08/22 13:00:57 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/08/22 13:00:57 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://172.16.80.54:8081
24/08/22 13:00:57 INFO Worker: Connecting to master localhost:7077...
24/08/22 13:00:57 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:7077 after 11 ms (0 ms spent in bootstraps)
24/08/22 13:00:57 INFO Worker: Successfully registered with master spark://localhost:7077
```

![](/images/development/spark/spark-cluster-deploy.png){: .align-center style="max-height: 400px" }
Master ë…¸ë“œì— Worker ë…¸ë“œë¥¼ í•˜ë‚˜ ë¶™ì¸ ìƒíƒœ
{: .align-caption .text-center .small .gray }

ì°¸ê³ ë¡œ Worker ë…¸ë“œ ìì²´ì˜ Spark UIë„ ìˆëŠ”ë°, ìš”ê±´ `http://localhost:8081`ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆë‹¤.

## spark-submit again

ì´ì œ Master ë…¸ë“œì™€ Worker ë…¸ë“œ ë‘˜ ë‹¤ êµ¬ì„±ì„ í–ˆìœ¼ë‹ˆ, ë‹¤ì‹œ `spark-submit`ì„ í•´ë³´ì.

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  ./hello-spark.py
```

![](/images/development/spark/spark-submit-on-cluster-mode.png){: .align-center style="max-height: 400px" }
`spark-submit`ì„ ì‹¤í–‰ í–ˆì„ ë•Œì˜ Master ë…¸ë“œì˜ Spark UI
{: .align-caption .text-center .small .gray }

Spark Appì´ ì‹¤í–‰ë˜ê³ , Completed ìƒíƒœë¡œ ë„˜ì–´ê°„ ê±¸ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  Worker ë…¸ë“œì—ì„œëŠ” ì´ë ‡ê²Œ ë‚˜ì˜¨ë‹¤.

![](/images/development/spark/spark-worker-view.png){: .align-center style="max-height: 400px" }
`spark-submit`ì„ ì‹¤í–‰ í–ˆì„ ë•Œì˜ Worker ë…¸ë“œì˜ Spark UI
{: .align-caption .text-center .small .gray }

<br/>

Spark UIë¥¼ í†µí•´ ì§€í‘œë¥¼ ì‚´í´ë³´ë©´, ê°„ë‹¨í•œ count ì‘ì–¸ì¸ë°ë„ CPU coreë¥¼ ë¬´ë ¤ `12 core`ë‚˜ ì‚¬ìš©í–ˆë‹¤! ì´ê²ƒì€ `spark-submit`ì„ í•  ë•Œ, ë”°ë¡œ ì‚¬ìš©í•  Coreì™€ Memory ìš©ëŸ‰ì„ ì§€ì •í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤!

```sh
$ spark-submit \
  --master spark://localhost:7077 \
  --total-executor-cores 2 \
  --executor-memory 500m \
  ./hello-spark.py
```

![](/images/development/spark/spark-submit-with-custom-spec.png){: .align-center style="max-height: 400px" }
Core ìˆ˜ì™€ Memory ìˆ˜ë¥¼ ì¡°ì •í•´ `spark-submit`ì„ ì‹¤í–‰í•œ ëª¨ìŠµ
{: .align-caption .text-center .small .gray }

# Spark Standalone ëª¨ë“œ

Master-Worker ë…¸ë“œë¡œ Spark í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•œ ì´ ë°©ì‹ì„ "Standalone" ëª¨ë“œë¼ê³  í•œë‹¤.

ë³¸ë˜ Spark í´ëŸ¬ìŠ¤í„°ëŠ” Master ë…¸ë“œ, Worker ë…¸ë“œ ë¿ë§Œ ì•„ë‹ˆë¼ "Cluster Manager"ë¼ëŠ” ì»´í¬ë„ŒíŠ¸ê°€ ìˆì–´ Spark í´ëŸ¬ìŠ¤í„° ìƒíƒœ ê´€ë¦¬, ë¦¬ì†ŒìŠ¤ í• ë‹¹, ì‘ì—… ë¶„ë°° ë“±ì˜ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

![](https://spark.apache.org/docs/latest/img/cluster-overview.png){: .align-center style="max-height: 400px" }

Standaloneì˜ ëœ»ì¸ "ìë¦½í˜•/ë…ë¦½í˜•"ë¼ëŠ” ëœ»ì— ë§ê²Œ Standalone ëª¨ë“œì—ì„œëŠ” Cluster Managerì˜ ì—­í• ì„ Spark ìì²´ì—ì„œ ìˆ˜í–‰í•œë‹¤. ë³´í†µ Production í™˜ê²½ì—ì„œëŠ” YARNì´ë‚˜ Mesosê°€ Cluster Manager ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ êµ¬ì¶•í•œë‹¤ê³  í•œë‹¤. ë§Œì•½ spark-on-kubernetesë¼ë©´, Kubernetesê°€ Cluster Managerì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê¸°ë„ í•œë‹¤.
