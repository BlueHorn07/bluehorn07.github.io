---
title: "Spark Speculative Execution"
toc: true
toc_sticky: true
categories: ["Spark"]
excerpt: ""
---

Databricks Certification ì·¨ë“ì„ ëª©í‘œë¡œ Apache Sparkë¥¼ â€œì œëŒ€ë¡œâ€ ê³µë¶€í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤. íšŒì‚¬ì—ì„  Databricks Unity Catalogë¥¼ ë„ì…í•˜ë ¤ê³  ë¶„íˆ¬í•˜ê³  ìˆëŠ”ë°ìš”. Sparkì™€ ì¢€ ì¹œí•´ì§ˆ ìˆ˜ ìˆì„ê¹Œìš”? ğŸ‡ ì „ì²´ í¬ìŠ¤íŠ¸ëŠ” [Development - Spark](/topic/development#apache-spark)ì—ì„œ í™•ì¸í•´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

# Spark Speculative Executionì´ë€

ë³¸ì¸ íšŒì‚¬ëŠ” 2018ë…„ë¶€í„° Databricksë¥¼ ë„ì…í•´ Sparkë¥¼ ì‚¬ìš©í•˜ê³  ìˆì—ˆë‹¤. ì‚¬ìš©í•œì§€ ì˜¤ë˜ ë˜ì–´ì„œ ê·¸ëŸ°ì§€ Databricks Jobë“¤ì— ì •ë§ ë‹¤ì–‘í•œ Spark Configë“¤ì´ ì„¸íŒ… ë˜ì–´ ìˆì—ˆë‹¤. ìš”ì¦˜ íšŒì‚¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” Spark Configë¥¼ ì •ë¦¬í•´ì„œ ë°œí‘œë¥¼ ì¤€ë¹„í•˜ê³  ìˆëŠ”ë°, `spark.speculation`ë¼ëŠ” configê°€ ë‚´ ëˆˆê¸¸ì„ ëŒê²Œ ë˜ì—ˆê³ , ê·¸ë ‡ê²Œ ì˜¤ëŠ˜ì˜ ì£¼ì œì¸ Speculative Executionì— ëŒ€í•´ ì‚´í´ë³´ê²Œ ë˜ì—ˆë‹¤.

Speculative Execution ê¸°ëŠ¥ì€ Spark `0.6.0`ë¶€í„° ë„ì…ëœ ìœ ì„œ ê¹Šì€ ê¸°ëŠ¥ì´ë‹¤. `spark.speculation`ë¼ëŠ” Configë¡œ ì œì–´í•˜ëŠ”ë°, ì„¤ëª…ì€ ì•„ë˜ì™€ ê°™ë‹¤.

![](/images/development/spark/spark-speculative-execution.png){: .align-center style="max-height: 400px" }
[Databricks: Best Practices for Enabling Speculative Execution on Large Scale Platforms](https://youtu.be/MIyQPz_R168?si=yGzbKIASEyG0WEfl)
{: .align-caption .text-center .small .gray }

> If set to "true", performs speculative execution of tasks. This means if one or more tasks are running slowly in a stage, they will be re-launched.	

ì´ ê¸°ëŠ¥ì€ Sparkì—ì„œ ì‹¤í–‰í•˜ëŠ” ì¼ë¶€ Taskê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ëŠë¦¬ê²Œ ì‹¤í–‰ë˜ê³  ìˆì„ ë•Œ, ê·¸ê²ƒì„ ì¸ì‹í•˜ê³  í•´ë‹¹ Taskë¥¼ ë‹¤ë¥¸ Worker ë…¸ë“œì—ì„œ ì¶”ê°€ë¡œ ì‹¤í–‰í•´ë³´ëŠ” ê¸°ë²•ì´ë‹¤. *speculative*ë¼ê³  ì´ë¦„ ë¶™ì€ ì´ìœ ëŠ” Taskê°€ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì„ ì¶”ì •(speculate)í•´ ëŒ€ë¹„í•œê¸° ë–„ë¬¸ì´ë¼ê³  í•œë‹¤.


ë§Œì•½ ë‹¤ë¥¸ ë…¸ë“œì— ë³µì œëœ ì‘ì—…ì´ ëŠë¦¬ê²Œ ì‹¤í–‰ë˜ë˜ ê¸°ì¡´ ì‘ì—…ë³´ë‹¤ ë¨¼ì € ëë‚˜ê²Œ ëœë‹¤ë©´, ê·¸ ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ê³  ê¸°ì¡´ ì‘ì—…ì€ ì·¨ì†Œ(kill) ì‹œí‚¨ë‹¤.

# Spark Configuration

ìš” ê¸°ëŠ¥ì€ ê¸°ë³¸ì ìœ¼ë¡œ êº¼ì ¸ìˆê³ , ê¸°ëŠ¥ì„ ì¼œê³  ì‹¶ë‹¤ë©´ `spark.speculation = true`ë¡œ ì„¤ì •í•˜ë©´ ëœë‹¤.

Speculationì—ì„œ ì‘ì—…ì„ ë³µì œí• ì§€ ë§ì§€ ì—¬ë¶€ íŒë‹¨ì€ `spark.speculation.interval`ì— ëª…ì‹œí•œ ì£¼ê¸°ë¡œ ì¼ì–´ë‚˜ë©°, ê¸°ë³¸ê°’ì€ `100ms`ë¡œ ë˜ì–´ ìˆë‹¤. ì´ë•Œ, `spark.speculation.minTaskRuntime` ê°’(default: 100ms)ë³´ë‹¤ ì˜¤ë˜ ì‹¤í–‰ë˜ëŠ” ì‘ì—…ì´ Speculation ëŒ€ìƒì´ ëœë‹¤. ë˜, `spark.speculation.quantile	` ê°’(default: 0.75)ì— ì˜í•´ í•´ë‹¹ Taskê°€ ì‹¤í–‰ë˜ëŠ” Stageì˜ Taskë“¤ì´ ì¼ì • ë¹„ìœ¨ ì´ìƒ ì‹¤í–‰ ì™„ë£Œ ë˜ì–´ì•¼ Speculation ì‘ì—…ì´ íŠ¸ë¦¬ê±° ë˜ê¸° ì‹œì‘í•œë‹¤.

Speculation ê²€ì‚¬ê°€ ì‹¤í–‰ë˜ë”ë¼ë„, ì‘ì—…ì´ ì¶©ë¶„íˆ ëŠë ¤ì•¼ Speculative Executionì´ íŠ¸ë¦¬ê±° ëœë‹¤. ê·¸ ê°’ì€ `spark.speculation.multiplier`ë¡œ íŒë‹¨í•˜ë©°, í•´ë‹¹ Taskê°€ ì‹¤í–‰ë˜ëŠ” Stageì—ì„œ í•¨ê»˜ ì‹¤í–‰ë˜ëŠ” ì‘ì—…ë“¤ì˜ í‰ê·  ì‘ì—… ì™„ë£Œ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ëª‡ ë°°(default: 1.5) ì´ìƒ ê±¸ë¦¬ë©´ ëŠë¦° ì‘ì—…ì´ë¼ê³  íŒë‹¨í•˜ê³ , ì‘ì—…ì„ ë³µì œí•œë‹¤.

# ë§ºìŒë§

ìš” ê¸°ëŠ¥ì€ ë³¸ë˜ Hadoopì—ì„œ ìœ ë˜í•œ ê¸°ëŠ¥ì´ë‹¤. í•˜ë‘¡ì—ì„œë„ ê°™ì€ ì´ë¦„ì¸ "Speculative Execution"ë¼ê³  ë¶ˆë €ë‹¤. ëŒ€ê·œëª¨ ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ì‘ì—…ì´ ì§€ì—°ë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì¤‘ìš”í•œ ê¸°ë²•ì´ë¼ê³  í•œë‹¤.

ë‹¤ë§Œ, Sparkì—ì„œ ì œê³µí•˜ëŠ” Default Configì˜ ê°’ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸°ì—ëŠ” ê´´ë¦¬ê°€ ìˆì–´ì„œ Linkedinì˜ ê²½ìš°ëŠ” ì•„ë˜ì™€ ê°™ì´ ê°’ì„ ì»¤ìŠ¤í…€í•˜ì—¬ ì‚¬ìš©í•˜ê³  ìˆë‹¤ê³  í•œë‹¤.

![](/images/development/spark/spark-speculative-execution-linkedin.png){: .align-center style="max-height: 300px" }
[Databricks: Best Practices for Enabling Speculative Execution on Large Scale Platforms](https://youtu.be/MIyQPz_R168?si=yGzbKIASEyG0WEfl)
{: .align-caption .text-center .small .gray }


# References

- [Databricks: Understanding speculative execution](https://kb.databricks.com/scala/understanding-speculative-execution)
- [Databricks: Best Practices for Enabling Speculative Execution on Large Scale Platforms](https://youtu.be/MIyQPz_R168?si=yGzbKIASEyG0WEfl)
- [Spark Configuration](https://spark.apache.org/docs/latest/configuration.html)

