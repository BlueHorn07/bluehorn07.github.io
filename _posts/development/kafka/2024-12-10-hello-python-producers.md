---
title: "Hello, Python Producers!"
toc: true
toc_sticky: true
categories: ["Kafka"]
excerpt: "ê¼­ Javaë¡œ Kafka Producer ê°œë°œí•  í•„ìš˜ ì—†ì–ì•„ Â¯\\\_(ãƒ„)_/Â¯ ê·¸ë¦¬ê³  Confluent Schema Registryë¡œ ìŠ¤í‚¤ë§ˆ ì •ì˜í•˜ê³  ë°ì´í„° ì ì¬ í•˜ê¸°"
---

# ì™œ Python Producerì— ê´€ì‹¬ì„ ê°–ê²Œ ë˜ì—ˆë‚˜ìš”?

"Kafka ê°œë°œì€ Javaê°€ ì¼ë°˜ì ì´ì£ "ë¼ëŠ” ë§ì„ ì°¸ ë§ì´ ë“¤ì€ ê²ƒ ê°™ë‹¤. ê·¸ëŸ°ë°, íšŒì‚¬ì—ì„œì˜ Kafka Producer Applicationì€ Pythonìœ¼ë¡œ ê°œë°œ ë˜ì–´ ìˆê³ , ì´ê±¸ë¡œ ê½¤ ë§ì€ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ê³  ìˆë‹¤!! (ì§€ê¸ˆë„!)

ê·¸ë ‡ê²Œ ìƒê°í•˜ë‹ˆ 'Python Producerë„ ë‚˜ì˜ì§€ ì•ŠëŠ”ë°?'ë¼ëŠ” ìƒê°ì´ ë“¤ê¸°ë„ í•˜ê³ , í•œë²ˆ ì œëŒ€ë¡œ ì •ë¦¬í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì´ ê¸€ì€ ê·¸ëŸ° ìƒê°ì´ ë“¤ì€ ë‚´ê°€ í…ŒìŠ¤íŠ¸ í•´ë³¸ Python Producer ì½”ë“œë“¤ì„ ì•„ì¹´ì´ë¸Œ í•˜ê³  ê¹¨ë‹¬ì€ ì ì„ ì ì€ ê¸€ì´ë‹¤.

ê¸€ì„ ì‹œì‘í•˜ê¸° ì „ì— ë¯¸ë¦¬ ë°íˆìë©´, ì§€ê¸ˆ íšŒì‚¬ì—ì„œ Confluent Cloudë¥¼ ì‚¬ìš©í•˜ê¸° ìˆê³ , ì•„ë˜ ì˜ˆì‹œ ì½”ë“œë“¤ ì—­ì‹œ `confluent_kafka` pip íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•¨ì„ ë°í™ë‹ˆë‹¤.
{: .notice }

# Simple Producer

keyì™€ value ê°’ë§Œ ì •í•˜ê³  Kafka í† í”½ì— ë°ì´í„°ë¥¼ ì˜ëŠ” ì˜ˆì œ ì…ë‹ˆë‹¤.

```py
from confluent_kafka import SerializingProducer

producer = SerializingProducer({
  'bootstrap.servers': 'xxxx.confluent.cloud:9092',
  'security.protocol': 'SASL_SSL',
  'sasl.mechanism': 'PLAIN',
  'sasl.username': 'xxxx',
  'sasl.password': 'xxxx',
})

def acked(err, msg):
    if err is not None:
        print(f'Failed to deliver message: {str(msg)}: {str(err)}')
    else:
        print(f'Message produced: {str(msg)}, offset: {msg.offset()}')

producer.produce(
  topic='my_topic',
  key='my_key',
  value='my_value',
  on_delivery=acked
)

producer.poll(1)
producer.flush()
```

Kafka Topicì—ì„œëŠ” ì „ë‹¬ ë°›ì€ `my_value` ê·¸ëŒ€ë¡œ ë°ì´í„°ê°€ ì ì¬ë©ë‹ˆë‹¤. í¬ìŠ¤íŠ¸ ì „ë°˜ì—ì„œ ì¤‘ìš”í•˜ê²Œ ë³¼ ì ì€ `value.serializer` ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ Serializerë¥¼ ë”°ë¡œ ì„¤ì •í•˜ì§€ ì•Šì•˜ëŠ”ë°, ì´ ê²½ìš° Value Serializerê°€ ì•„ë¬´ê²ƒë„ ì§€ì •ë˜ì§€ ì•Šê³  `None`ìœ¼ë¡œ ì„¸íŒ… ë©ë‹ˆë‹¤.

ì´ ê²½ìš°, ì•„ë¬´ëŸ° Serialization ì—†ì´ ë°”ë¡œ Kafkaë¡œ produce ë©ë‹ˆë‹¤. [confluentinc/confluent-kafka-python](https://github.com/confluentinc/confluent-kafka-python/blob/v2.6.1/src/confluent_kafka/serializing_producer.py#L136-L146)

ë‹¨, `str`ì´ ì•„ë‹Œ `int`, `dict`, `list` ë“±ë“± ë‹¤ë¥¸ ëª¨ë“  íƒ€ì…ì€ ì•„ë˜ì™€ ê°™ì€ ì˜¤ë¥˜ì™€ í•¨ê»˜ Kafkaì— ë°ì´í„°ê°€ ì ì¬ë˜ì§€ ì•Šê³  ì‹¤íŒ¨í•©ë‹ˆë‹¤.

```bash
TypeError: a bytes-like object is required, not 'int'
```

# String Producer

```py
from confluent_kafka import SerializingProducer
from confluent_kafka.serialization import StringSerializer

producer = SerializingProducer({
  'bootstrap.servers': 'xxxx.confluent.cloud:9092',
  'security.protocol': 'SASL_SSL',
  'sasl.mechanism': 'PLAIN',
  'sasl.username': 'xxxx',
  'sasl.password': 'xxxx',
  'key.serializer': StringSerializer('utf_8'),
  'value.serializer': StringSerializer('utf_8'),

})

producer.produce(
  topic='my_topic',
  key='my_key',
  value='my_value',
  on_delivery=acked
)
```

ì—¬ê¸°ì„œë¶€í„° `acked()`ì™€ `poll()`, `flush()`ì— ëŒ€í•œ ë¶€ë¶„ì€ ë¹¼ê³  ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤. String ProducerëŠ” `StringSerializer`ë¥¼ Serializerë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

`StringSerializer('utf_8')`ë¡œ ì„¤ì •í•˜ëŠ”ë°, `utf_8`ì€ ì½”ë±(codec) ê°’ì„ ë§í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì´ `utf_8`ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ë§Œì•½ stringì´ ì•„ë‹Œ `int(12345)`ì™€ ê°™ì€ ê°’ì„ ì¤€ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ SerializationErrorë¥¼ ê²ªìŠµë‹ˆë‹¤.

```bash
confluent_kafka.error.ValueSerializationError: KafkaError{code=_VALUE_SERIALIZATION,val=-161,str="'int' object has no attribute 'encode'"}
```

# Confluent Schema Registry

ì—¬ê¸°ì„œ ì ê¹! ë’¤ì— ì´ì–´ì§ˆ Json Producerì™€ Avro Producerë¥¼ í…ŒìŠ¤íŠ¸ í•˜ê¸° ì „ì— ë°˜ë“œì‹œ Schema Registryì— Schemaê°€ ì„¸íŒ… ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” Serializerì— `schema_registry` client ê°’ì„ ë„˜ê²¨ì¤˜ì•¼ í•©ë‹ˆë‹¤.

```py
from confluent_kafka.schema_registry import SchemaRegistryClient

sr_client = SchemaRegistryClient({
    'url': 'https://xxxx.confluent.cloud',
    'basic.auth.user.info': '{Key}:{Secret}'.format(Key='xxxx', Secret='xxxx'),
})
```

ì—¬ê¸°ì„œë¶€í„° ë‹¤ë£¨ëŠ” ë¶€ë¶„ì´ ì´ ê¸€ì„ ì“°ê²Œ ëœ ê°€ì¥ í° ê³„ê¸° ì…ë‹ˆë‹¤. ìƒê°ë³´ë‹¤ ë³µì¡ í–ˆê±°ë“ ìš”. ì¼ë‹¨ Serializer ì¢…ë¥˜ë³„ë¡œ ì‚¬ë ˆë¥¼ ì‚´í´ë´…ì‹œë‹¤.

# Json Producer w/ Json Schema

## Json Schema

ì¼ë‹¨ "User"ë¼ëŠ” Json Schema ì˜ˆì‹œë¶€í„° ì‚´í´ë´…ë‹ˆë‹¤.

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "User",
  "description": "A Confluent Kafka Python User",
  "type": "object",
  "properties": {
    "name": {
      "description": "User's name",
      "type": "string"
    },
    "favorite_number": {
      "description": "User's favorite number",
      "type": "number",
      "exclusiveMinimum": 0
    },
    "favorite_color": {
      "description": "User's favorite color",
      "type": "string"
    }
  },
  "required": [ "name", "favorite_number", "favorite_color" ]
}
```

ì²«ì¤„ë¶€í„° `$schema`ë¼ëŠ” ìš”ìƒí•œ ë…€ì„ì´ ë“±ì¥í•˜ëŠ”ë°, Json Schemaì— ëŒ€í•œ ìŠ¤í‚¤ë§ˆ í‘œì¤€ ë²„ì „(draft)ì„ ì ì–´ì£¼ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. Json ìŠ¤í‚¤ë§ˆì˜ í‘œì¤€ì€ ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ì—…ë°ì´íŠ¸ ë˜ê³  ìƒˆë¡œìš´ ë²„ì „(draft)ê°€ ë‚˜ì˜¤ë©´ì„œ ê¸°ëŠ¥ê³¼ ë¬¸ë²•ì´ ë³€í™” í•©ë‹ˆë‹¤. `$schema` ë¶€ë¶„ì€ ì •ì˜í•œ ìŠ¤í‚¤ë§ˆê°€ ì–´ë–¤ í‘œì¤€ ë²„ì „ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆëŠ”ì§€ ëª…ì‹œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. íŠ¹ì • ë²„ì „ì—ì„œë§Œ ì§€ì›í•˜ëŠ” ê¸°ëŠ¥ë“¤ì´ ìˆë‹¤ê³  í•˜ë‹ˆ ë²„ì „ì— ìœ ì˜í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì´ì–´ì§€ëŠ” `title`, `description` ë“±ì˜ ê°’ì€ ë‹¹ì—°í•œ ê°’ë“¤ì˜ ë‚˜ì—´ì´ë¼ ë³„ë„ë¡œ ì„¤ëª…í•˜ì§„ ì•Šê² ìŠµë‹ˆë‹¤.

ì•„! ê·¸ë¦¬ê³  JSON schemaë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì•„ë˜ì˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤.

```bash
$ pip install jsonschema
```

## Json Producer

Json Producer ì½”ë“œë¥¼ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•©ë‹ˆë‹¤.

```py
from confluent_kafka import SerializingProducer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.serialization import StringSerializer
from confluent_kafka.schema_registry.json_schema import JSONSerializer

schema_str = """
  {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "User",
    "description": "A Confluent Kafka Python User",
    "type": "object",
    "properties": {
      "name": {
        "description": "User's name",
        "type": "string"
      },
      "favorite_number": {
        "description": "User's favorite number",
        "type": "number",
        "exclusiveMinimum": 0
      },
      "favorite_color": {
        "description": "User's favorite color",
        "type": "string"
      }
    },
    "required": [ "name", "favorite_number", "favorite_color" ]
  }
"""

producer = SerializingProducer({
  'bootstrap.servers': 'xxxx.confluent.cloud:9092',
  ...
  'key.serializer': StringSerializer('utf_8'),
  'value.serializer': JSONSerializer(
    schema_registry_client=sr_client,
    schema_str=schema_str,
  ),
})

producer.produce(
  topic='my_topic,
  key='my_user',
  value={
    'name': 'Gildong-Hong',
    'favorite_number': 18,
    'favorite_color': 'blue',
  },
  on_delivery=acked
)
```


## Serializer Configs

ëª‡ê°€ì§€ Configurationì´ ìˆìŠµë‹ˆë‹¤.

- `auto.register.schemas` (default: True)
  - ë§Œì•½ Topicì— Schemaê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ìë™ìœ¼ë¡œ ë“±ë¡í•´ì£¼ëŠ” ì˜µì…˜
  - Schema ì´ë¦„ì€ ì•„ë˜ì˜ `subject.name.strategy`ì— ë”°ë¼ ê²°ì •ë˜ëŠ”ë°
    - Default ê°’ì¸ TopicName Strategyë¥¼ ë”°ë¥¸ë‹¤ë©´, `{TopicName}-key`, `{TopicName}-value`ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.
- `subject.name.strategy` (default: topic_subject_name_strategy)
- `normalize.schemas` (default: False)
  - ëŒ€ì¶© ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ ì»¬ëŸ¼ ìˆœì„œê¹Œì§€ ë”°ë¥´ë„ë¡ validationì„ ìˆ˜í–‰í•  ê²ƒì¸ê°€ì— ëŒ€í•œ ì˜µì…˜ì…ë‹ˆë‹¤.
- `use.latest.version` (default: False)
  - í† í”½ì— ë“±ë¡ëœ Schemaì˜ ìµœì‹  ë²„ì „ìœ¼ë¡œ Serializationì„ í•  ê²ƒì´ëƒì— ëŒ€í•œ ì˜µì…˜ì…ë‹ˆë‹¤.
  - ìœ„ì—ì„œ ì„¤ëª…í•œ `auto.register.schemas` ì˜µì…˜ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
  - Confluentì—ì„œ í† í”½ì— ë“±ë¡ëœ ìµœì‹  ìŠ¤í‚¤ë§ˆë¥¼ ì°¾ì•„ì„œ ê·¸ê±¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. [[confluent-kafka-python] json_schema.py](https://github.com/confluentinc/confluent-kafka-python/blob/master/src/confluent_kafka/schema_registry/json_schema.py#L246-L249)

```py
producer = SerializingProducer({
  'bootstrap.servers': 'xxxx.cloud:9092',
  ...
  'key.serializer': StringSerializer('utf_8'),
  'value.serializer': JSONSerializer(
    schema_registry_client=sr_client,
    schema_str=schema_str,
    conf = {
        'auto.register.schemas': False,
        'use.latest.version': True,
    }
  ),
})
```

`use.latest.version` ì˜µì…˜ ê´€ë ¨í•´ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì¢€ë” í•´ë³´ë‹ˆ, `schema_str` ê°’ì€ ì—¬ì „íˆ ë„£ì–´ì¤˜ì•¼ í–ˆìŠµë‹ˆë‹¤. `None`ì´ëŸ° ê°’ì„ ë„£ì–´ì„œë„ ì•ˆ ë©ë‹ˆë‹¤. ì•ì—ì„œ ì •ì˜í•œ ëŒ€ë¡œ `schema_str` ê°’ì„ ë„£ì–´ì•¼ í•˜ë©°, ì œê³µí•œ `schema_str` ê°’ì˜ Json ìŠ¤í‚¤ë§ˆì— ë”°ë¼ validationë„ ì´ë¤„ì§‘ë‹ˆë‹¤. ê·¸ì €, Schema Registryì— ì‹ ê·œë¡œ ë“±ë¡í•˜ì§€ ì•Šê³  ê¸°ì¡´ ê²ƒì„ ì‚¬ìš©í•œë‹¤ì˜ ì¼„ì„­?ë§Œì„ ì œê³µí•˜ëŠ” ì˜µì…˜ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. (ì•„ì‰½)


# Avro Producer w/ Avro Schema

## Avro Schema

Avro í¬ë§·ì— ëŒ€í•´ì„  ì§€ë‚œ í¬ìŠ¤íŠ¸ì¸ ["Hello, Avro!"](/2024/11/15/hello-avro/) í¬ìŠ¤íŠ¸ì—ì„œ ë‹¤ë¤˜ìœ¼ë‹ˆ ìì„¸í•œ ì£¼ì†Œ ì„¤ëª…ì€ ìƒë½í•˜ê² ìŠµë‹ˆë‹¤ ã…ã…
ì™œ ì“°ëŠëƒê³  ëˆ„êµ°ê°€ ë¬»ëŠ”ë‹¤ë©´ Json ë³´ë‹¤ ì••ì¶•ë¥ ì´ ì¢‹ì•„ì„œ ì‚¬ìš©í•œë‹¤ë¡œ ë‹µë³€í•  ìˆ˜ ìˆì„ ë“¯ í•©ë‹ˆë‹¤. (ê·¸ë¦¬ê³  Union Schema ê¸°ëŠ¥ë„ìš”!)

```json
{
    "name": "User",
    "type": "record",
    "fields": [
        {
            "name": "name",
            "type": "string"
        },
        {
            "name": "favorite_number",
            "type": "long"
        },
        {
            "name": "favorite_color",
            "type": "string"
        }
    ]
}
```

ìš°ì„  ìœ„ì™€ ê°™ì´ ì •ì˜í•œ Avro Schemaë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

## Avro Producer

ì•ì„œ ì‚´í´ë³¸ [JSON Producer](#json-producer)ì˜ ì‚¬ë¡€ì™€ ì •ë§ ë¹„ìŠ·í•©ë‹ˆë‹¤. Serializerì— Schema Registry Clientë¥¼ ì „ë‹¬í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.

```py
from confluent_kafka import SerializingProducer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.serialization import StringSerializer
from confluent_kafka.schema_registry.avro import AvroSerializer

schema_str = """
...
"""

producer = SerializingProducer({
  'bootstrap.servers': 'xxxx.confluent.cloud:9092',
  ...
  'key.serializer': StringSerializer('utf_8'),
  'value.serializer': AvroSerializer(
    schema_registry_client=sr_client,
    schema_str=schema_str,
  ),
})

producer.produce(
  topic='my_topic,
  key='my_user',
  value={
    'name': 'Gildong-Hong',
    'favorite_number': 18,
    'favorite_color': 'blue',
  },
  on_delivery=acked
)
```

## Serializer Config

Producer configì— ëŒ€í•œ ë¶€ë¶„ë„ `JsonSerializer`ì˜ ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤. `auto.register.schemas`ë¡œ Topicì— ì‹ ê·œ/ë³€ê²½ëœ ìŠ¤í‚¤ë§ˆë¥¼ ìë™ìœ¼ë¡œ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ë§ºìŒë§

Kafka ê·¸ë¦¬ê³  Confluent í”Œë«í¼ì— ëŒ€í•´ ì–´ë ´í’‹ì´ ì•Œë˜ ê²ƒë“¤ì´ ì§ì ‘ ì½”ë“œë¥¼ êµ¬ì„±í•˜ê³  ì˜µì…˜ë“¤ì„ ì‹¤í—˜í•´ë³´ë©´ì„œ ì–»ê²Œ ë˜ëŠ”ê²Œ ë§ì•„ì§€ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

ìš”ì¦˜ì—ëŠ” ì´ë¡ ì„ ê³µë¶€í•˜ëŠ” ê²ƒë³´ë‹¤ ê·¸ê±¸ í™œìš©í•˜ê³  ì ìš©í•˜ê³ , í”„ë¡œë•ì„ ë§Œë“¤ì–´ ê°€ëŠ” ê²ƒì´ ë” ê°€ì¹˜ ìˆë‹¤ê³  ëŠë¼ê²Œ ë˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë¹ ë¥´ê²Œ ë°°ì›Œì„œ ë¹ ë¥´ê²Œ ì ìš©í•˜ê³ , ê·¸ë¦¬ê³  ë¹ ë¥´ê²Œ ì‹¤íŒ¨í•˜ê³ (ã…‹ã…‹). ê¸€ì„ ì“°ëŠ” ì‹œì ì—ëŠ” 2024ë…„ì´ ì´ì œ í•œ ë‹¬ë„ ì±„ ë‚¨ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‚´ë…„ì—ëŠ” ë­˜ í•´ë³¼ê¹Œ? ì‹œê°„ì„ ì–´ë–»ê²Œ ì¨ë³¼ê¹Œ? ê³ ë¯¼í•˜ê³  ìƒìƒ í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ë…„ì— ì¬ë°ŒëŠ” ê²ƒë“¤ì€ ì™•ì°½ í•  ìˆ˜ ìˆê¸¸!! ğŸ„

ì´ê²ƒì €ê²ƒ Serializerë¥¼ ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸ í•´ë³¼ ë•Œ, `confluentinc/confluent-kafka-python`ì— ìˆëŠ” [examples](https://github.com/confluentinc/confluent-kafka-python/blob/master/examples) í´ë”ì˜ ì˜ˆì‹œ ì½”ë“œë“¤ì´ ë§ì´ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. Producer ë§ê³ ë„ Consumer ìª½ ì˜ˆì‹œ ì½”ë“œë„ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì‹œê¸¸!!
