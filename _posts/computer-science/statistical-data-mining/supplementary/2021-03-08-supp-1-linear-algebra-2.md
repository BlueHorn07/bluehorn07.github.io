---
title: "Supp-1: Linear Algebra - 2"
layout: post
use_math: true
tags: [linear_algebra, applied_statistics]
---


2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í†µê³„ì  ë°ì´í„°ë§ˆì´ë‹' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- Eigen value & Eigen vector
- Trace
- Vector Calculus
- Matrix Calculus
  - Quadratic Form

<hr/>

### Eigen value & Eigen vector

<br><span class="statement-title">Definition.</span> eigen value & eigen vector<br>

For $A \in \mathbb{R}^{n \times n}$, $\lambda \in \mathbb{C}$ is called an \<**eigen value**\> of $A$ if

$$
A \mathbf{x} = \lambda \mathbf{x} \quad \text{for some} \; \mathbf{x} \in \mathbb{R} \setminus \{\mathbf{0}\}
$$

Here, $\mathbf{x}$ is called an \<**eigen vector**\> of $A$ associated with $\lambda$.

<br><span class="statement-title">Note.</span><br>

$\det (A - \lambda I_n) = 0$ if and only if $\lambda$ is an \<eigen value\>.

<div class="proof" markdown="1">

<span class="statement-title">*Proof*.</span><br>

$A\mathbf{x} = \lambda\mathbf{x}$ì—ì„œ ì •ë¦¬í•˜ë©´ $(A - \lambda I_n) \mathbf{x} = 0$ì„ ì–»ëŠ”ë‹¤. ì´ë•Œ, $\mathbf{x}$ì˜ ì¡°ê±´ì— ì˜í•´ $\mathbf{x} \ne \mathbf{0}$ì´ë‹¤. ì¦‰, $\mathbf{x}$ëŠ” non-trivial solutionì„ ê°–ëŠ”ë‹¤ëŠ” ë§ì´ë‹¤.

ì–´ë–¤ í–‰ë ¬ $A$ì— ëŒ€í•´ $A$ê°€ invertibleì´ë¼ë©´, $A\mathbf{x} = 0$ì—ì„œ $\mathbf{x}$ëŠ” trivial solution $\mathbf{0}$ë§Œì„ ì–»ëŠ”ë‹¤. ë”°ë¼ì„œ, $(A - \lambda I_n) \mathbf{x} = 0$ì—ì„œ $\mathbf{x}$ì´ non-trivial solutionì„ ê°€ì§€ë ¤ë©´, $(A - \lambda I_n)$ì´ non-invertible, ì¦‰ $\det(A - \lambda I_n) = 0$ì´ì–´ì•¼ í•œë‹¤!

</div>

<br/>

$\det(A-\lambda I_n)$ëŠ” $\lambda$ì— ëŒ€í•œ $n$-th order polynomialì´ë‹¤. ë”°ë¼ì„œ, $A$ëŠ” ì •í™•íˆ $n$ê°œì˜ complex eigenvalues (up to multiplicity)ë¥¼ ê°–ëŠ”ë‹¤. (*Fundamental Theorem of Algebra*) ì´ëŸ° $\det (A - \lambda I_n)$ì„ \<**íŠ¹ì„± ë‹¤í•­ì‹ Characteristic Polynomial**\>ì´ë¼ê³  ë¶€ë¥¸ë‹¤!

<br/>

í–‰ë ¬ $A$ë¥¼ ì„ í˜•ë³€í™˜ì˜ ê´€ì ì—ì„œ ì‚´í´ë³¸ë‹¤ë©´, \<eigen vector\>ëŠ” <span class="half_HL">ì„ í˜•ë³€í™˜ $A$ë¥¼ ì ìš©í–ˆì„ ë•Œì˜ ê²°ê³¼ê°€ ìì‹ ì˜ ìƒìˆ˜ë°°ê°€ ë˜ëŠ” 0ì´ ì•„ë‹ˆ ë²¡í„°ë¥¼ ë§í•œë‹¤.</span>

ì´ëŸ° ì„±ì§ˆì€ \<eigen vector\>ê°€ ì„ í˜•ë³€í™˜ $A$ ì•„ë˜ì—ì„œ ë°©í–¥ì´ ë³´ì¡´ë˜ê³ , í¬ê¸°(scale)ë§Œ ë³€í•˜ëŠ” ë²¡í„°ì„ì„ ì˜ë¯¸í•œë‹¤.

<div class="img-wrapper">
  <img src="https://t1.daumcdn.net/cfile/tistory/277D6547525CFB120B" width="250px">
  <p markdown="1">Image from ['ë‹¤í¬ í”„ë¡œê·¸ë˜ë¨¸'](https://darkpgmr.tistory.com/105)</p>
</div>

ì˜ˆë¥¼ ë“¤ì–´, ì§€êµ¬ì˜ ìì „ìš´ë™ì´ë¼ëŠ” 3ì°¨ì› íšŒì „ë³€í™˜ì„ ìƒê°í•  ë•Œ, ì´ íšŒì „ ë³€í™˜ì— ì˜í•´ ë³€í•˜ì§€ ì•ŠëŠ” \<eigen vector\>ëŠ” íšŒì ì¶•ì´ ë˜ë©°, ê·¸ëŒ€ì˜ \<eigen value\>ëŠ” $1$ì´ ëœë‹¤!

<br/>

\<eigen vector\>ì™€ \<eigen value\>ëŠ” ë’¤ì—ì„œ ì‚´í´ë³¼ \<Eigen Decomposition\> ë‹¤ë¥¸ ë§ë¡œ \<Spectral Decomposition\>ì—ì„œ ì£¼ìš”í•˜ê²Œ ì‚¬ìš©ëœë‹¤. ì´ë•Œ, ëª¨ë“  ì •ë°©í–‰ë ¬ì— ëŒ€í•´ \<Eigen Decomposition\>ì´ ê°€ëŠ¥í•œ ê²ƒì€ ì•„ë‹ˆë‹¤. ì´ê²ƒì´ ê°€ëŠ¥í•˜ë ¤ë©´, $n\times n$ í–‰ë ¬ $A$ê°€ $n$ê°œì˜ linearly indenpendent eigen vectorë¥¼ ê°€ì§ˆ ë•Œë§Œ ê°€ëŠ¥í•˜ë‹¤! (ì¡°ê±´ì´ ê½¤ ê¹Œë‹¤ë¡­ë‹¤...!)

ğŸ‘‰ [Spectral Decomposition]({{"/2021/03/14/supp-1-linear-algebra-3.html#spectral-decomposition" | relative_url}})

<hr/>

<br><span class="statement-title">Definition.</span> Trace<br>

The sum of all diagonal elements of $A \in \mathbb{R}^{n\times n}$ is called the \<trace\> of $A$, denoted $\text{tr}(A)$.

<br><span class="statement-title">Properties.</span><br>

- $\text{tr}(A) = \text{tr}(A^T)$
- $\text{tr}(A+B) = \text{tr}(A) + \text{tr}(B)$
- $\text{tr}(AB) = \text{tr}(BA)$, for $A \in \mathbb{R}^{n\times p}$, $B \in \mathbb{R}^{p\times n}$ ğŸˆ
- $\text{tr}(AA^T) = \text{tr}(A^TA)$
- $\displaystyle \text{tr}(A) = \sum^n_{i=1} \lambda_i$, where $\lambda_i$'s are eigenvalues of $A$. ğŸˆ

ğŸˆ ì´ëª¨ì§€ê°€ ë¶™ì€ ì„±ì§ˆì€ íŠ¹íˆ ì¤‘ìš”í•œ ì„±ì§ˆì…ë‹ˆë‹¤! ìœ ë„ ê³¼ì •ì„ ê¼­ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤!

<hr/>

## Matrix Calculus

ì¼ì°¨ì› ë³€ìˆ˜ì— ëŒ€í•´ì„œ í•˜ë˜ \<Calculus\>ë¥¼ ë” ë†’ì€ ì°¨ì›ì—ì„œ í•˜ëŠ” ê²ƒì´ \<**Vector Calculus**\> ë˜ëŠ” \<**Matrix Calculus**\>ì´ë‹¤.

<br><span class="statement-title">Definition.</span> Vector Calculus<br>

Let $\mathbf{a} \in \mathbb{R}^{p \times 1}$ represents a mapping $f: \mathbb{R}^p \rightarrow \mathbb{R}$. Then, $\mathbf{a}^T \mathbf{x} = a_1 x_1 + a_2 x_2 \cdots + a_p x_p$

$$
\frac{\partial}{\partial \mathbf{x}} \left( \mathbf{a}^T \mathbf{x} \right) \overset{\text{def}}{=} \left( \frac{\partial}{\partial x_i} \left( \mathbf{a}^T \mathbf{x}\right) \right)_{1 \le i \le p} = \mathbf{a}
$$

ìœ„ì˜ ìƒí™©ì€ scalarì¸ $\mathbf{a}^T \mathbf{x}$ë¥¼ vector $\mathbf{x}$ë¡œ ë¯¸ë¶„í•˜ëŠ” ìƒí™©ì´ë‹¤!

<br><span class="statement-title">Definition.</span> Matrix Calculus<br>

Let $A \in \mathbb{R}^{n\times p}$ represents a mapping $f: \mathbb{R}^p \rightarrow \mathbb{R}^n$. Then 

$$
A \mathbf{x} = 
\begin{pmatrix}
a_{11} x_1 + a_{12} x_2 + \cdots a_{1p} x_p \\
a_{21} x_1 + a_{22} x_2 + \cdots a_{2p} x_p \\
\vdots \\
a_{n1} x_1 + a_{n2} x_2 + \cdots a_{np} x_p \\
\end{pmatrix}
= \begin{pmatrix}
\mathbf{a}_1^T \mathbf{x} \\
\mathbf{a}_2^T \mathbf{x} \\
\vdots \\
\mathbf{a}_n^T \mathbf{x} \\
\end{pmatrix}
$$

1\. vector-by-vector

$$
\frac{\partial}{\partial \mathbf{x}} \left( A \mathbf{x} \right) \overset{\text{def}}{=} \left( \frac{\partial}{\partial \mathbf{x}} \left( \mathbf{a}_i^T \mathbf{x} \right) \right)_{1 \le i \le n} = \left( \mathbf{a}_i^T \right)_{1 \le i \le n} = A
$$

2\. \<**Quadratic Form**\> Calculus

Let $A \in \mathbb{R}^{n \times n}$, then A \<Quadratic Form\> $\mathbf{x}^T A \mathbf{x}$ is 

$$
\mathbf{x}^T A \mathbf{x} = \sum^n_{i=1} x_i \left( A \mathbf{x}\right)_i = \sum^n_{i=1} x_i \left( \sum^n_{j=1} a_{ij} x_j \right) = \sum^n_{i=1} \sum^n_{j=1} a_{ij} x_i x_j
$$

Take derivative on $\mathbf{x}^T A \mathbf{x}$

$$
\begin{aligned}
\frac{\partial}{\partial \mathbf{x}} \left( \mathbf{x}^T A \mathbf{x} \right) &\overset{\text{def}}{=} \left( \frac{\partial}{\partial x_i} \left( \mathbf{x}^T A \mathbf{x} \right) \right)_{1 \le i \le n} \\
&= \left( \frac{\partial}{\partial x_k} \left( \sum^n_{i=1} \sum^n_{j=1} a_{ij} x_i x_j \right) \right)_{1 \le k \le n}
\end{aligned}
$$

ì´ë•Œ, ì†ìœ¼ë¡œ ìŠ¤ì¼€ì¹˜í•´ì„œ í™•ì¸í•´ë³´ë©´, $\displaystyle\frac{\partial}{\partial x_k} \left(\mathbf{x}^T A \mathbf{x}\right)$ëŠ” $\mathbf{x}^T A \mathbf{x}$ë¥¼ ë‚˜ì—´ í–ˆì„ ë•Œ $k$ë²ˆì§¸ í–‰, $k$ë²ˆì§¸ ì—´ ë¶€ë¶„ì„ ë¯¸ë¶„í•˜ëŠ” í–‰ìœ„ë‹¤. ê·¸ë˜ì„œ ì´ê²ƒì„ ì˜ ì •ë¦¬í•˜ë©´, ì•„ë˜ì˜ ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤.

$$
\frac{\partial}{\partial x_k} \left(\mathbf{x}^T A \mathbf{x}\right) = \sum^n_{i=1} a_{ik}
 x_i + \sum^n_{j=1} a_{kj}x_j = \left(A^T\mathbf{x}\right)_k + \left(A\mathbf{x}\right)_k
$$

ë”°ë¼ì„œ, $\displaystyle\frac{\partial}{\partial \mathbf{x}} \left( \mathbf{x}^T A \mathbf{x} \right)$ì€

$$
\frac{\partial}{\partial \mathbf{x}} \left( \mathbf{x}^T A \mathbf{x} \right) = \left( \left(A^T\mathbf{x}\right)_k + \left(A\mathbf{x}\right)_k \right)_{1\le k \le n} = A^T \mathbf{x} + A \mathbf{x} = \left( A^T + A \right) \mathbf{x}
$$

ì—¬ê¸°ì„œ ë§Œì•½ $A$ê°€ symmetric matrixë¼ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

$$
\frac{\partial}{\partial \mathbf{x}} \left( \mathbf{x}^T A \mathbf{x} \right) = \left( A^T + A \right) \mathbf{x} = 2A \mathbf{x}
$$

2\. \<**Quadratic Form**\> Calculus - (2)

ì´ë²ˆì—” $\mathbf{x}$ë¡œ í•œë²ˆë” ë¯¸ë¶„ì„ í•´ë³´ì!

$$
\frac{\partial^2}{\partial \mathbf{x} \partial \mathbf{x^T}} \left( \mathbf{x}^T A \mathbf{x} \right) \overset{\text{def}}{=} \left( \frac{\partial^2}{\partial x_j \partial x_i} \left( \mathbf{x}^T A \mathbf{x} \right) \right)_{1 \le i, \, j \, \le n} = \frac{\partial}{\partial \mathbf{x}}  \left( \left( A^T + A \right) \mathbf{x} \right) = (A^T + A)
$$

<hr/>

ì´ì–´ì§€ëŠ” ë‚´ìš©ì—ì„  \<Spectral Decomposition\>ì™€ \<Singular Value Decomposition\> ë“± ì„ í˜• ë³€í™˜ì˜ ì¢€ë” ë”¥í•œ ë‚´ìš©ì„ ë‹¤ë£¬ë‹¤! ğŸ¤¯

ğŸ‘‰ [Supp-1: Linear Algebra - 3]({{"2021/03/14/supp-1-linear-algebra-3.html" | relative_url}})