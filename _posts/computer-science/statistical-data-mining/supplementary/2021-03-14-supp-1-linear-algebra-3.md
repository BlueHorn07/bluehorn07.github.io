---
title: "Supp-1: Linear Algebra - 3"
layout: post
use_math: true
tags: [linear_algebra, applied_statistics]
---


2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í†µê³„ì  ë°ì´í„°ë§ˆì´ë‹' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- [Spectral Decomposition; Eigen Decomposition](#spectral-decomposition)
- [Singular Value Decomposition](#singular-value-decomposition)
  - Low Rank Approximation

<hr/>

### Set-up

<br><span class="statement-title">formulas.</span><br>

1\. $\displaystyle UU^T = \sum^n_{i=1} \mathbf{u}_i \mathbf{u}_i^T$, where $U = \left( \mathbf{u}_1, \dots, \mathbf{u}_n \right) \in \mathbb{R}^{n \times n}$

2\. $\displaystyle UDU^T = \sum^n_{i=1} d_i \mathbf{u}_i \mathbf{u}_i^T$, where $D = \text{diag}(d_i)$

í–‰ë ¬ê³±ì„ í‘œí˜„í•˜ëŠ” ìœ ìš©í•œ ë°©ì‹ì´ë‹ˆ ìµìˆ™í•´ì§€ë©´ ì¢‹ë‹¤! ì•ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ë‚´ìš©ì—ì„œ ìì£¼ ë“±ì¥í•œë‹¤!

<br><span class="statement-title">Definition.</span> Orthogonal Matrix<br>

An \<**orthogonal matrix**\> $U$ is a matrix such that $UU^T = U^TU = I_n$.

<hr/>

### Spectral Decomposition

<br><span class="statement-title">Theorem.</span> Spectral Decomposition; Eigen Decomposition<br>

For a real **symmetric** matrix $A \in \mathbb{R}^{n\times n}$, there exists a diagonal matrix $D = \text{diag}(d_1, \dots, d_n)$ and an orthogonal matrix $U$ s.t. $A = UDU^T$.

ì¦‰, ëª¨ë“  symmetric matrixëŠ” $UDU^T$ì˜ í˜•íƒœë¡œ decompose ê°€ëŠ¥í•¨ì„ ë§í•œë‹¤!

<br><span class="statement-title">Note.</span><br>

- Each $d_i$ is an real **eigenvalue** of $A$.
- $\mathbf{u}_i$ is the eigenvector associated with $d_i$, where $U = \left( \mathbf{u}_1, \dots, \mathbf{u}_n \right)$.
- $\displaystyle A = UDU^T = \sum^n_{i=1} d_i \mathbf{u}_i \mathbf{u}_i^T$


\<Spectral Decomposition\>ì€ ê¸°í•˜í•™ì  ì´í•´ê°€ ìˆ˜ë°˜ë˜ì–´ì•¼ í•œë‹¤.

ë¨¼ì €, orthogonal matrix $U$ì— ëŒ€í•´ $U$ëŠ” ì„ í˜•ë³€í™˜ì—ì„œ ì¼ì¢…ì˜ rotation matrixì˜ ì—­í• ì„ í•œë‹¤.

$$
\mathbf{x} \longrightarrow U \mathbf{x}
$$

ì´ì œ $A\mathbf{x}$ë¥¼ í•´ì„í•˜ê¸° ìœ„í•´ $UDU^T\mathbf{x}$ë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ì„í•´ë³´ì.

1\. $U^T \mathbf{x}$; íšŒì „ì„ í†µí•´ ì¢Œí‘œì¶• ë³€í™˜

$U^T$ëŠ” íšŒì „ ë³€í™˜ì„ ìˆ˜í–‰í•œë‹¤. ë”°ë¼ì„œ, $e_1$, $e_2$ ì¢Œí‘œê³„ ìœ„ì— ìˆë˜ $\mathbf{x}$ë¥¼ $u_1$, $u_2$ ì¢Œí‘œê³„ë¡œ íšŒì „ ë³€í™˜í•œë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/spectral-decomposition-1.jpg" | relative_url }}" width="280px">
</div>

ì´ë•Œ, $u_1$, $u_2$ëŠ” $U^T$ì˜ ê° ì—´ìœ¼ë¡œì¨ $A$ì˜ eigen vectorì´ë‹¤.

ê·¸ë¦¬ê³  $U^T \mathbf{x}$ë¥¼ ê³„ì‚°í•´ë³´ë©´,

$$
U^T \mathbf{x} = \left(u_1, u_2 \right) \cdot \mathbf{x} = \begin{pmatrix}
    (\mathbf{x}^T u_1) \cdot u_1 \\
    (\mathbf{x}^T u_2) \cdot u_2
\end{pmatrix} 
$$

ê°€ ë˜ê³ , ì´ê²ƒì€ $\mathbf{x}$ë¥¼ $u_1$, $u_2$ ì¶•ìœ¼ë¡œ \<projection\>í•œ ê²ƒê³¼ ê°™ë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/spectral-decomposition-2.jpg" | relative_url }}" width="280px">
</div>

2\. $D \left( U^T \mathbf{x} \right)$; ìŠ¤ì¹¼ë¼ ê³±

$D$ëŠ” diagnomal matrixì´ê¸° ë•Œë¬¸ì— $u_1$, $u_2$ ë°©í–¥ì˜ ë²¡í„°ì— ëŒ€í•œ ìŠ¤ì¹¼ë¼ ê³±ì„ í•˜ëŠ” ì—­í• ì´ë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/spectral-decomposition-3.jpg" | relative_url }}" width="280px">
</div>

3\. $U \left( D U^T \mathbf{x} \right)$; ì›ë˜ì˜ ì¢Œí‘œì¶•ìœ¼ë¡œ ì—­-íšŒì „

ë§ˆì§€ë§‰ìœ¼ë¡œ ì²˜ìŒì— ê³±í•œ $U^T$ì˜ ì—­-íšŒì „ ë³€í™˜ì¸ $U$ë¥¼ ì ìš©í•´ ë‹¤ì‹œ $e_1$, $e_2$ì˜ ì¢Œí‘œê³„ë¡œ ë˜ëŒë ¤ ì¤€ë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/spectral-decomposition-4.jpg" | relative_url }}" width="280px">
</div>

ê·¸ë˜ì„œ ì‹ì„ ì •ë¦¬í•˜ë©´, ì•„ë˜ì™€ ê°™ë‹¤.

$$
UDU^T \mathbf{x} = UD \begin{pmatrix}
    u_1^T \mathbf{x} \\
    \vdots \\
    u_n^T \mathbf{x}
\end{pmatrix} = U \begin{pmatrix}
    d_1 u_1^T \mathbf{x} \\
    \vdots \\
    d_n u_n^T \mathbf{x}
\end{pmatrix} = d_1 u_1 u_1^T \mathbf{x} + \cdots + d_n u_n u_n^T \mathbf{x}
$$

<hr/>

### Singular Value Decomposition

\<Sepctral Theorem\>ì€ ëŒ€ì¹­ í–‰ë ¬ì— ëŒ€í•´ì„œ ê¸°ìˆ í•œ ì •ë¦¬ì˜€ë‹¤. ì´ê²ƒì„ ì¼ë°˜ì ì¸ í˜•íƒœì˜ í–‰ë ¬ë¡œ ì¼ë°˜í™”í•œ ê²ƒì´ ë°”ë¡œ \<**íŠ¹ì´ê°’ ë¶„í•´ Singular Value Decomposition**\>ì´ë‹¤. ğŸ˜

<br><span class="statement-title">Theorem.</span> Singular Value Decomposition<br>

For any $n \times p$ matrix $A$, there exist matrices $U \in \mathbb{R}^{n\times n}$, $D \in \mathbb{R}^{n\times p}$, and $V \in \mathbb{R}^{p\times p}$ s.t.

$$
A = UDV^T
$$

where

- $D = \text{diag}(d_1, \dots, d_p)$ with $d_i \ge 0$
  - $d_j$s are called \<**singular value**\> of $A$.
- $U$ is an orthogonal matrix from $AA^T = U(\Sigma\Sigma^T)U^T$
- $V$ is an orthogonal matrix from $A^T A = V(\Sigma^T \Sigma)V^T$

#### Low Rank Approximation

SVDë¥¼ ì˜ ì´ìš©í•˜ë©´, í–‰ë ¬ $A$ì— ëŒ€í•œ \<Low Rank Aprroximation\> $A_k$ë¥¼ ìœ ë„í•  ìˆ˜ ìˆë‹¤.

Let $A = UDV^T$ and assume that $n \gg p$, then

$$
A = \begin{bmatrix}
  \vert & & \vert \\
  \mathbf{u}_1 & \cdots & \mathbf{u}_n \\
  \vert & & \vert \\
\end{bmatrix}
\begin{bmatrix}
  d_1 & & \\
      & \ddots \\
      & & d_p \\
      & O &
\end{bmatrix}
\begin{bmatrix}
 - & \mathbf{v}_1^T & - \\
 & \vdots & \\
 - & \mathbf{v}_p^T & - \\
\end{bmatrix}
= d_1 \mathbf{u}_1 \mathbf{v}_1^T + \cdots + d_p \mathbf{u}_p \mathbf{v}_p^T
$$

ì´ë•Œ, í‘œê¸°ì˜ í¸ì˜ë¥¼ ìœ„í•´ singular value $d_i$ì— ëŒ€í•´ descending orderë¡œ í‘œê¸°ë¥¼ í•œë‹¤.

$$
\text{where} \quad d_1 \ge d_2 \cdots \ge d_p
$$

ì£¼ëª©í•  ì ì€ ì‹ì˜ ìš°ë³€ì˜ $\mathbf{u}_i \mathbf{v}_i^T$ì€ rank-1 matrixë¼ëŠ” ì ì´ë‹¤. ì¦‰, SVDë¥¼ í•˜ê²Œ ë˜ë©´ í–‰ë ¬ $A$ë¥¼ rank-1ì˜ matrixë¡œ ë¶„í•´í•œ ê²ƒì´ ëœë‹¤.

ì´ì œ ìœ„ì˜ ê²°ê³¼ë¥¼ ê°€ì§€ê³  Approximation $A_k$ë¥¼ ìœ ë„í•  ìˆ˜ ìˆë‹¤.

$$
A_k = \begin{bmatrix}
  \vert & & \vert \\
  \mathbf{u}_1 & \cdots & \mathbf{u}_k \\
  \vert & & \vert \\
\end{bmatrix}
\begin{bmatrix}
  d_1 & & \\
      & \ddots & \\
      &  & d_k \\
      & O &
\end{bmatrix}
\begin{bmatrix}
 - & \mathbf{v}_1^T & - \\
 & \vdots & \\
 - & \mathbf{v}_k^T & - \\
\end{bmatrix}
= d_1 \mathbf{u}_1 \mathbf{v}_1^T + \cdots + d_k \mathbf{u}_k \mathbf{v}_k^T
$$

ì¦‰, $A_k$ëŠ” $A$ë¥¼ SVDë¡œ ë¶„í•´í•´ í‘œí˜„í•œ ê²ƒì—ì„œ ì•ì˜ $k$ê°œì˜ rank-1 matrixë¥¼ ëª¨ì€ ê²ƒì´ë‹¤! ìš°ë¦¬ê°€ $d_i$ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ í‘œí˜„í–ˆê¸° ë•Œë¬¸ì—, ë’¤ë¡œ ê°ˆìˆ˜ë¡ ì‘ì€ $d_j$ë¥¼ ì–»ê²Œ ë˜ì–´ ìˆë‹¤. ê·¸ë˜ì„œ $A_k$ëŠ” ì•ì˜ $k$ê°œ $d_i$ë§Œì„ ì„ íƒí•´ $A$ë¥¼ ê·¼ì‚¬í•œ ê²ƒì´ë‹¤!

ì´ë•Œ, \<Low Rank Approximation\>ì˜ errorëŠ” ì•„ë˜ì™€ ê°™ì´ \<Frobenius norm\>ìœ¼ë¡œ ì •ì˜í•œë‹¤.

$$
\begin{aligned}
\| A - A_k \|^2_F &= \text{tr}\left( (A-A_k)^T (A-A_k) \right) \\  
  &= d_{k+1}^2 + d_{k+2}^2 + \cdots + d_p^2
\end{aligned}
$$

ê·¸ë˜ì„œ, ë§Œì•½ ë’·ë¶€ë¶„ì˜ $d_{k+1}, \cdots d_p$ì˜ í¬ê¸°ê°€ ì‘ë‹¤ë©´, Low Rank ApproxëŠ” ì¶©ë¶„íˆ ì •í™•í•œ ê·¼ì‚¬ë¥¼ ìˆ˜í–‰í•¨ì„ ë³´ì¥í•  ìˆ˜ ìˆë‹¤!!

ps. ì´ëŸ° Low Rank ApproxëŠ” ìƒê°ë³´ë‹¤ ìì£¼ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì´ë¼ê³  í•œë‹¤.

ps. Netflixì˜ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ Contestì—ì„œ ì´ SVDë¥¼ í™œìš©í•´ Low Rank Approxë¥¼ í•˜ëŠ” ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ íŒ€ì´ ìš°ìŠ¹ì„ ì°¨ì§€í–ˆë‹¤ê³  í•œë‹¤.

<hr/>

ì§€ê¸ˆê¹Œì§€ í–‰ë ¬ì„ ë¶„í•´í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì¸ \<Spectral Decomposition\>ê³¼ \<Singular Value Decomposition\>ë¥¼ ì‚´í´ë´¤ë‹¤. ì´ ë‘ ê°œë…ì€ ì´ì–´ì§€ëŠ” ë‚´ìš©ì¸ í–‰ë ¬ì˜ \<Nonnegative Definite\>, \<Positive Definite\>ë¥¼ ì •ì˜í•  ë•Œ ë°”íƒ•ì´ ëœë‹¤.

ğŸ‘‰ [Supp-1: Linear Algebra - 4]({{"/2021/03/27/supp-1-linear-algebra-4.html" | relative_url}})