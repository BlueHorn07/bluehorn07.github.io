---
title: "Additive Model & GAM"
toc: true
toc_sticky: true
categories: ["Applied Statsitcs"]
---


2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í†µê³„ì  ë°ì´í„°ë§ˆì´ë‹' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- [Additive Model](#additive-model)
  - Backfitting Algorithm
- [GAM; Generalized Additive Model](#gam-generalized-additive-model)

<hr/>

### Additive Model

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Additive Model<br>

The regression model

$$
E (Y \mid X_1, \dots, X_p) = \alpha + f_1(X_1) + \cdots + f_p(X_p)
$$

is called an \<additive model\>.

</div>

<span class="half_HL">It assumes that there is no interaction effect.</span>

Therefore, it can effectively avoid "the curve of dimensionality".

<br/>

âœ¨ Goal: How can we estimate $f_i(x_i)$?

ì´ë•Œ ì“°ëŠ” ì ‘ê·¼ë²•ì´ ë°”ë¡œ \<Backfitting Algorithm\>ì´ë‹¤.

<br/>

ë³´í†µ ìš°ë¦¬ê°€ $f_j$ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ $f_k$ì— ëŒ€í•œ í•¨ìˆ˜ë¥¼ ì•Œê³  ìˆì„ ë•Œ, $f_j$ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì€ ì•„ì£¼ ì‰½ë‹¤. ê·¸ëƒ¥ 1ì°¨ì› ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤!

ì´ë ‡ê²Œ ë‹¤ë¥¸ í•¨ìˆ˜ë¥¼ fix ì‹œì¼œë‘ê³ , í•¨ìˆ˜ í•˜ë‚˜ë¥¼ fitting í•˜ëŠ” ê¸°ë²•ì„ \<Backfitting Algorithm\>ì´ë¼ê³  í•œë‹¤.'

<div class="math-statement" markdown="1">

<span class="statement-title">Algorithm.</span> Backfitting Algorithm<br>

1\. Initialize: <br/>
\- $\hat{\alpha} = \bar{y}$<br/>
\- for $\forall \, j$, $\hat{f}_j = 0$

2\. Repeat until converge

find an estiamtor $\hat{f}_j$ based on $$\left\{ x_i, \; y_i - \hat{\alpha} - \displaystyle \sum_{k\ne j} \hat{f}_k(x_{ik}) \right\}^n_{i=1}$$

</div>

ğŸ’¥ ì´ë•Œ, 2ë²ˆì§¸ ìŠ¤í…ì—ì„œ \<smoothing spline\>ì´ë‚˜ \<kernel method\> ë“±ì˜ ë‹¤ë¥¸ non-parameteric methodë“¤ì„ ì ìš©í•´ë³¼ ìˆ˜ë„ ìˆë‹¤.

\<Backfitting Algorithm\>ì€ Convex optimizationê³¼ ë¹„ìŠ·í•˜ë‹¤ê³  í•˜ë©°, êµ‰ì¥íˆ ë¹ ë¥´ê²Œ ìˆ˜ë ´í•œë‹¤ê³  í•œë‹¤! ğŸ˜²

<hr/>

### GAM; Generalized Additive Model

\<GAM; Generalized Additive Model\>ì€ ê°•ë ¥í•˜ë©´ì„œë„ ê°„ë‹¨í•œ í†µê³„ì  í…Œí¬ë‹‰ ì¤‘ í•˜ë‚˜ì´ë‹¤. 1986ë…„, ESLì˜ ê³µë™ì €ìì¸ "Trevor Hastie"ì™€ "Robert Tibshirani"ì— ì˜í•´ ê°œë°œëœ ë°©ë²•ì´ë‹¤.

<div class="statement" markdown="1">

Relationships btw the individual predictors and the dependent variable follow <u>smooth patterns</u> that can be linear or non-linear.

</div>

ì¦‰, <span class="half_HL">GAMì€ \<Additive Model\>ì—ì„œ $f_j$ê°€ smooth non-parametricì¸ ëª¨ë¸</span>ì´ë‹¤!

<br/>

'DataCamp'ì˜ [ìœ íŠœë¸Œ ì˜ìƒ](https://youtu.be/6V_VvweZkoI)ì—ì„œëŠ” \<GAM\>ì´ \<Linear Model\>ê³¼ \<Bloack-BOX ML\> ëª¨ë¸ì˜ ì¤‘ê°„ ì •ë„ì— ìœ„ì¹˜í•˜ëŠ” ëª¨ë¸ì´ë¼ê³  ì†Œê°œí•œë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/GAM-1.png" | relative_url }}" width="450px">
  <p markdown="1">Image from ['DataCamp'](https://youtu.be/6V_VvweZkoI)</p>
</div>

í†µê³„ì  ëª¨ë¸ì€ \<Interpretability\>ì™€ \<Flexibility\>ì— trade-offê°€ ìˆëŠ”ë°, ì™¼í¸ê³¼ ì˜¤ë¥¸í¸ì´ ê°ê°ì„ ì˜ë¯¸í•œë‹¤.

\<GAM\>ì€ ë”± ì¤‘ê°„ ì •ë„ì— ìœ„ì¹˜í•œ ëª¨ë¸ë¡œ, ì ë‹¹í•œ \<Interpretability\>ì™€ ì ë‹¹í•œ \<Flexibility\>ë¥¼ ì œê³µí•œë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/GAM-2.png" | relative_url }}" width="650px">
  <p markdown="1">Image from ['DataCamp'](https://youtu.be/6V_VvweZkoI)</p>
</div>

ìœ„ì˜ ê·¸ë¦¼ì€ \<GAM\>ì—ì„œ ì‚¬ìš©ëœ \<smooth basis function\>ë“¤ì„ í‘œí˜„í•œ ê²ƒì´ë‹¤. ì™¼ìª½ ê·¸ë¦¼ì€ ëª¨ë“  basis func.ì— ë™ì¼í•œ coeff.ë¥¼ ì¤€ ê·¸ë¦¼ì´ê³ , ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ í•™ìŠµì„ í†µí•´ ê° basis func.ì— íŠœë‹ëœ coeff.ë¥¼ ì¤€ ê·¸ë¦¼ì´ë‹¤.

<br/>

'multithreaded'ì— ê²Œì‹œëœ [í¬ìŠ¤íŠ¸](https://multithreaded.stitchfix.com/blog/2015/07/30/gam/)ì—ì„œëŠ” GAMì˜ ì¥ì ìœ¼ë¡œ

(1) Interpretability<br/>
(2) Flexibility & Automation<br/>
(3) Regularization

ì„ ê¼½ëŠ”ë‹¤.

ì´ ì¤‘ì—ì„œ ë¨¼ì € "**Regularization**"ë¶€í„° ì‚´í´ë³´ì. smooth functionì„ ì¶”ì •í•˜ëŠ” **GAM**ì€ "smoothness"ë¥¼ ì»¨íŠ¸ë¡¤ í•˜ëŠ” tuning parameter $\lambda$ê°€ ì¡´ì¬í•œë‹¤. ì´ê²ƒì„ í†µí•´ overfittingì„ ë°©ì§€í•˜ê³ , ì „ì²´ predictorê°€ wiggle í•´ì§€ëŠ” ê²ƒì„ ë°©ì§€í•œë‹¤.

'DataCamp'ì˜ [ìœ íŠœë¸Œ ì˜ìƒ](https://www.youtube.com/watch?v=vckDyqI8tS8)ì— ë”°ë¥´ë©´, \<GAM\>ì€ ì•„ë˜ì˜ ìˆ˜ì‹ì— ë”°ë¼ ëª¨ë¸ì˜ Wigglinessë¥¼ ì¡°ì •í•œë‹¤ê³  í•œë‹¤.

$$
\text{Fit} = \text{Likelihood} - \lambda \times \text{Wiggliness}
$$

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/GAM-3.png" | relative_url }}" width="650px">
  <p markdown="1">Image from ['DataCamp'](https://youtu.be/8doPTpkAWDQ)</p>
</div>

ë˜ëŠ” basis func.ì˜ ìˆ˜ë¡œë„ smoothnessë¥¼ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.

<div class="img-wrapper">
  <img src="{{ "/images/statistical-data-mining/GAM-4.png" | relative_url }}" width="650px">
  <p markdown="1">Image from ['DataCamp'](https://youtu.be/8doPTpkAWDQ)</p>
</div>

<br/>

\<GAM\>ì€ input feature ìˆ˜ê°€ ì—¬ëŸ¬ ê°œì¼ ë•Œë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ, ê° input featureê°€ independent í•˜ë‹¤ëŠ” \<additive model\>ì˜ ê°€ì •ì„ ì‚¬ìš©í•œë‹¤!

ìì„¸í•œ ë‚´ìš©ì€ 'DataCamp'ì˜ ì˜ìƒì„ í†µí•´ ì‚´í´ë³´ì.

ğŸ‘‰ [[YouTube] R Tutorial: Multivariate GAMs](https://youtu.be/8doPTpkAWDQ)

<hr/>

#### ì°¸ê³ ìë£Œ

- [post from 'multithreaded'](https://multithreaded.stitchfix.com/blog/2015/07/30/gam/)
- [[YouTube] R Tutorial: Nonlinear Modeling in R with GAMs](https://youtu.be/6V_VvweZkoI)
- [[YouTube] R Tutorial: Basis functions and smoothing](https://www.youtube.com/watch?v=vckDyqI8tS8)
- [[YouTube] R Tutorial: Multivariate GAMs](https://youtu.be/8doPTpkAWDQ)