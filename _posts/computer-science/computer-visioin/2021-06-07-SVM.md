---
title: "SVM; Support Vector Machine"
toc: true
toc_sticky: true
categories: ["Computer Vision", "Data Mining"]
---


ë³¸ ê¸€ì€ 2020-2í•™ê¸° "ì»´í“¨í„° ë¹„ì „" ìˆ˜ì—…ì˜ ë‚´ìš©ì„ ê°œì¸ì ìœ¼ë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- [Introduction to SVM](#introduction-to-svm)
- [Convex Optimization](#convex-optimization)
- [Dual Problem](#dual-problem)
- [Soft-margin SVM](#soft-margin-svm)

ğŸ’¥ (before start) SVMì—ì„œëŠ” class labelì´ $\\{ -1, +1\\}$ë¡œ ì¸ì½”ë”© ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤.

<hr/>

### Introduction to SVM

<div class="img-wrapper">
  <img src="{{"/images/computer-science/computer-vision/svm-1.png" | relative_url }}" style="width:70%;">
</div>

Linearly Separableí•œ ë°ì´í„° í¬ì¸íŠ¸ì˜ ì§‘í•©ì´ ìˆì„ ë•Œ, ë‘ ì§‘í•©ì„ ë‚˜ëˆ„ëŠ” hyper-planeì€ ë¬´í•œíˆ ë§ì´ ê·¸ë¦´ ìˆ˜ ìˆë‹¤. \<SVM; Support Vector Machine\>ì€ ë¬´í•œíˆ ë§ì€ hyper-plane ì¤‘ ì–´ë–¤ ê²ƒì´ ê°€ì¥ bestì¸ì§€ ì°¾ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.

\<SVM\>ì—ì„œëŠ” best hyper-planeì„ ì•„ë˜ì™€ ê°™ì´ ì •ì˜í•œë‹¤.

<div class="statement" style="font-size: large" align="center">

The hyper-plane that maximizes the margin!

</div>

ì¦‰, \<SVM\>ì€ "**margin**"ì„ ìµœëŒ€í™”í•˜ëŠ” hyper-planeì¸ ê²ƒì´ë‹¤. ê·¸ëŸ¼ "**margin**"ì€ ë¬´ì—‡ì¼ê¹Œ? ì‰½ê²Œ ì„¤ëª…í•˜ë©´, ë°ì´í„°ë¥¼ ì„ í˜•ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” hyper-planeì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°ì˜ ê±°ë¦¬ "**margin**"ì´ë¼ê³  í•œë‹¤.

<div class="img-wrapper">
  <img src="{{"/images/computer-science/computer-vision/svm-2.png" | relative_url }}" style="width:40%;">
</div>

ìœ„ ê·¸ë¦¼ì„ ë³´ë©´, $B_1$ê³¼ $B_2$ ëª¨ë‘ ë°ì´í„°ì…‹ì„ ì˜ ë¶„í• í•˜ê³  ìˆì§€ë§Œ, $B_1$ì´ $B_2$ ë³´ë‹¤ ë” ì—¬ìœ ë¡­ê²Œ ë¶„ë¦¬í•˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ì´ë•Œ, <span class="half_HL">ì–¼ë§ˆë‚˜ ì—¬ìœ ë¡­ê²Œ ë¶„ë¦¬í•˜ê³  ìˆëŠ”ì§€ë¥¼ hyper-planeê³¼ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°ì˜ ê±°ë¦¬ë¡œ ìˆ˜ì¹˜í™”</span>í•  ìˆ˜ ìˆìœ¼ë©°, ì´ê²ƒì´ ë°”ë¡œ "**margin**"ì´ë‹¤.

<div class="notice" markdown="1">

"margin"ì— ëŒ€í•œ ì‹ì„ ìœ ë„í•˜ê¸° ìœ„í•´ hyper-planeì„ ì•„ë˜ì™€ ê°™ì´ ì •ì˜í•´ë³´ì.

$$
w^T x + b = 0
$$

ì´ë•Œ, $w$ëŠ” hyper-planeì˜ ë²•ì„ ë²¡í„°ë‹¤.

hyper-planeì„ ì˜ ì •ì˜í–ˆìœ¼ë©´, "**margin**"ì€ "**ì ê³¼ í‰ë©´ ì‚¬ì´ ê±°ë¦¬ ê³µì‹**"ì„ í†µí•´ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.

<div class="theorem" markdown="1" align="center">

$$
\text{dist}(x_0) = \frac{ | w^T x_0 + b | }{ \| w \| }
$$

\* ë§Œì•½ marginì˜ ë°©í–¥ì„ êµ¬ë¶„í•˜ê³  ì‹¶ë‹¤ë©´, ë¶„ì ë¶€ë¶„ì˜ ì ˆëŒ“ê°’ì„ ì“°ì§€ ì•Šìœ¼ë©´ ëœë‹¤!

</div>

ë˜ëŠ” ìœ„ì˜ ì‹ì„ ì•½ê°„ ë³€í˜•í•´ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤.

$$
\text{dist}(x_0) = \frac{ y_0 \cdot (w^T x_0 + b) }{ \| w \| }
$$

ì‚¬ì‹¤ ìš°ë¦¬ê°€ í‰ì†Œì— ì“°ëŠ” "margin"ì˜ ê°œë…ì€ ìœ„ì˜ ì‹ì—ì„œ ë¶„ìì¸ $y_0 \cdot (w^T x_0 + b)$ì´ë‹¤. ì´ "margin"ì€ class labelì´ *correctly classified* ë˜ì—ˆë‹¤ë©´, í•­ìƒ ì–‘ìˆ˜ì˜ ê°’ì„ ê°–ëŠ”ë‹¤. (linearly separable)í•œ SVMì—ì„œëŠ” ì´ margin ê°’ì´ í•­ìƒ ì–‘ìˆ˜ë‹¤!

ìœ„ì˜ ì -í‰ë©´ ê±°ë¦¬ ê³µì‹ì„ ë°”íƒ•ìœ¼ë¡œ 'the minimial distance'ì¸ "**margin**"ì„ í‘œí˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

$$
\begin{aligned}
\text{margin}
&= \min_i \left[ \text{dist}(x_i) \right] \\
&= \min_i \left[ \frac{ y_i \cdot (w^T x_i + b) }{ \| w \| } \right] \\
&= \frac{1}{\| w \|} \min_i \left[ y_i \cdot (w^T x_i + b) \right]
\end{aligned}
$$

</div>

ì´ì— ìœ„ì—ì„œ ìœ ë„í•œ "margin"ì— ëŒ€í•œ ì‹ìœ¼ë¡œ \<SVM\>ì˜ ìµœì í™” ë¬¸ì œë¥¼ ê¸°ìˆ í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

$$
\underset{w, b}{\text{argmax}} \left[ \frac{1}{\| w \|} \min_i \left[ y_i \cdot (w^T x_i + b) \right] \right]
$$

ì´ì œ \<SVM\>ì˜ ìµœì í™” ë¬¸ì œë¥¼ ì •ì˜í–ˆìœ¼ë‹ˆ, ì´ ë¬¸ì œì˜ solutionì„ ì°¾ì•„ë³´ì!

<hr/>

### Convex Optimization

$$
\underset{w, b}{\text{argmax}} \left[ \frac{1}{\| w \|} \min_i \left[ y_i \cdot (w^T x_i + b) \right] \right]
$$

ë¨¼ì €, \<SVM\>ì˜ ìµœì í™” ì‹ì—ì„œ ì•½ê°„ì˜ normalizationì„ ìˆ˜í–‰í•´ì¤€ë‹¤.

ê·¸ ì´ìœ ëŠ” hyper-plane $w^T x + b$ë‚˜ $c(w^T x + b)$ë‚˜ ë™ì¼í•œ í‰ë©´ì„ ì •ì˜í•˜ê¸° ë•Œë¬¸ì—, ë¬¸ì œì˜ ììœ ë„ë¥¼ ë‚®ì¶”ê³  ì‹ì„ í’€ê¸° ì‰½ê²Œ ë³€í˜•í•˜ê¸° ìœ„í•¨ì´ë‹¤!

ìš°ë¦¬ëŠ” ì•„ë˜ì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” $w$ì™€ $b$ë¡œ hyper-planeì˜ ì‹ì„ normalize í•œë‹¤.

$$
w^T x_{+} + b = 1 \quad \text{and} \quad w^T x_{-} + b = -1
$$

ì´ë•Œ, $x_{+}$ì™€ $x_{-}$ëŠ” hyper-planeì´ ë¶„í• í•˜ëŠ” labelì—ì„œ "margin"ì„ ì´ë£¨ëŠ” ì ì´ë‹¤. ìš°ë¦¬ëŠ” ì´ ì ì„ "**support vector**"ë¼ê³  ë¶€ë¥¸ë‹¤!

<small>ps) ë³¸ì¸ì€ ìœ„ì™€ ê°™ì´ ë‘ support vectorì— ëŒ€í•œ ê°’ì´ $\pm1$ì´ ë˜ë„ë¡ normí•˜ëŠ”ê²Œ ê°€ëŠ¥í•œì§€ ì˜ ì´í•´ê°€ ì•ˆ ë˜ì—ˆëŠ”ë°, ì˜ ìƒê°í•´ë³´ë‹ˆê¹Œ ë‘ support vectorê°€ ê°™ì€ marginì„ ê°€ì§€ë„ë¡ ì„¤ì •í•˜ë©´ ë˜ëŠ” ê±°ì˜€ë‹¤.[^1] ë‹¤ë¥´ê²Œ ìƒê°í•˜ë©´, ìœ„ì™€ ê°™ì´ normalize í•˜ëŠ” ê²ƒ ì—­ì‹œ ìµœì í™” ì‹ì— contraintë¡œ ì‘ìš©í•  ê±°ë¼ëŠ” ìƒê°ì´ ë“ ë‹¤.</small>

ìœ„ì™€ ê°™ì´ ì„¤ì •í•˜ë©´, ê³§ ì•„ë˜ì˜ ì‹ì´ ì„±ë¦½í•œë‹¤.

$$
\text{margin} = \frac{1}{\| w \|}
$$

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ \<SVM\>ì˜ ìµœì í™” ì‹ì„ ë‹¤ì‹œ ì“°ë©´ ì•„ë˜ì™€ ê°™ë‹¤. ìš°ë¦¬ê°€ "support vector"ì˜ ê°’ì´ $\pm1$ì´ ë˜ë„ë¡ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì— ê¸°ì¡´ ì‹ì—ì„œ "contraint" í…€ì´ ë¶™ëŠ”ë‹¤.

$$
\underset{w, b}{\text{argmax}} \frac{1}{\| w \|} \cdot 1 \quad \text{subject to} \quad  y_i (w^T x_i + b) \ge 1 \;\; \forall i
$$

ì´ë•Œ ìœ„ì˜ ìµœì í™” ì‹ì€ ì•„ë˜ì˜ **convex optimization**ê³¼ ë™ì¹˜ë‹¤.

$$
{\color{red}{\underset{w, b}{\text{argmin}} \frac{1}{2} \| w \|^2}} \quad \text{subject to} \quad  y_i (w^T x_i + b) \ge 1 \;\; \forall i
$$

<hr/>

### Dual Problem

ìœ„ì˜ ê³¼ì •ì„ í†µí•´ ìš°ë¦¬ëŠ” \<SVM\>ì„ "Convex Optimization" ë¬¸ì œì˜ í˜•íƒœë¡œ ì˜ ìœ ë„í–ˆë‹¤.

$$
\min_{w, b} \frac{1}{2} \| w \|^2 \quad \text{subject to} \quad  y_i (w^T x_i + b) \ge 1 \;\; \forall i
$$

ì´ë•Œ, "Convex Optimization" ë¬¸ì œì— "Lagrange Multiplier" $\lambda_i$ë¥¼ ë„ì…í•˜ë©´ \<Dual Problem\>ì´ë¼ëŠ” ìƒˆë¡œìš´ ìµœì í™” ë¬¸ì œë¥¼ ì–»ëŠ”ë‹¤. ì´ê²ƒì„ \<Dual Problem\>ì´ë¼ê³  í•˜ë©° \<SVM\>ì˜ ê²½ìš°ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

$$
\max_{\lambda} \left[ \min_{w, b} L(w, b, \lambda) \right] \quad \text{where} \quad L(w, b, \lambda) = \frac{1}{2} \| w \|^2 - \sum_{i=1}^n {\color{red}{\lambda_i}} \{ y_i (w^T x_i + b) - 1 \} \quad \text{and} \quad \lambda_i \ge 0
$$

Lagrange Multiplier $\lambda_i$ë¥¼ ë„ì…í•˜ë©´ì„œ, ê¸°ì¡´ ì‹ì˜ contraint ë¶€ë¶„ì´ ì‹ $L(w, b, \lambda)$ë¡œ í¡ìˆ˜ ë˜ì—ˆë‹¤.

ì‹ì´ ê¸°ì¡´ë³´ë‹¤ í›¨ì”¬ ë³µì¡í•´ì¡Œì§€ë§Œ, ìœ„ì˜ ì‹ì€ ì •ë§ ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì‰½ê²Œ í’€ë¦°ë‹¤!! ğŸ˜²

$$
\frac{\partial L(w, b, \lambda)}{\partial w} = w - \sum_{i=1}^n \lambda_i y_i x_i = 0 \quad \iff \quad w = \sum_{i=1}^n \lambda_i y_i x_i
$$

$$
\frac{\partial L(w, b, \lambda)}{\partial b} = 0 - \sum_{i=1}^n \lambda_i y_i = 0 \quad \iff \quad \sum_{i=1}^n \lambda_i y_i = 0
$$

ì™€ìš° ì •ë§ ê°„ë‹¨í•˜ì§€ ì•Šì€ê°€?? ì´ê²ƒì€ ìš°ë¦¬ê°€ Lagrange Multiplierë¥¼ ë„ì…í•˜ë©´ì„œ, contraintë¥¼ í¡ìˆ˜í–ˆê¸° ë•Œë¬¸ì— ë‹¨ìˆœíˆ í¸ë¯¸ë¶„ ë§Œìœ¼ë¡œ ìµœì í™” ì‹ì˜ í•´(è§£)ë¥¼ êµ¬í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤!! ğŸ˜†

<br/>

í•˜ì§€ë§Œ ì•„ì§ ë¬¸ì œë¥¼ ì™„ì „íˆ í•´ê²°í•œ ê²ƒì€ ì•„ë‹ˆë‹¤. ìµœì ì˜ $w$ëŠ” ì°¾ì•˜ì§€ë§Œ, ê·¸ ì‹ì— $\lambda_i$ê°€ ìˆì–´ ì™„ì „í•œ è§£ë¥¼ ì–»ì€ ê²ƒì´ ì•„ë‹ˆë‹¤. ìœ„ì˜ ê³¼ì •ì€ ê¸°ì¡´ì˜ \<Dual Problem\>ì˜ ìµœì í™” ë¬¸ì œë¥¼ ì•„ë˜ì™€ ê°™ì´ í•œêº¼í’€ ë²—ê¸´ ê²ƒì— ë¶ˆê³¼í•œë‹¤.

$$
\begin{aligned}
&\max_{\lambda} \left[ \frac{1}{2} \| w \|^2 - \sum_{i=1}^n \lambda_i \{ y_i (w^T x_i + b) - 1 \} \right] \\
&\text{where} \quad w = \sum_{i=1}^n \lambda_i y_i x_i \quad \text{and} \quad \sum_{i=1}^n \lambda_i y_i = 0 \quad \text{and} \quad \lambda_i \ge 0
\end{aligned}
$$

ì´ë•Œ ìœ„ì˜ ì‹ì—ì„œ $\sum \lambda_i y_i = 0$ë¥¼ ì ìš©í•´ ì‹ì˜ ì˜¤ë¥¸ìª½ í…€ì„ ì•„ë˜ì™€ ê°™ì´ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

$$
\max_{\lambda} \left[ \frac{1}{2} \| w \|^2 - \sum_{i=1}^n \lambda_i ( y_i w^T x_i - 1 ) \right]
= \max_{\lambda} \left[ \frac{1}{2} \| w \|^2 - \sum_{i=1}^n \lambda_i y_i w^T x_i  + \sum_{i=1}^n \lambda_i \right]
$$

ì´ë²ˆì—ëŠ” $w = \sum \lambda_i y_i x_i$ë¥¼ ëŒ€ì…í•˜ì.

$$
\begin{aligned}
\max_{\lambda} \left[ \frac{1}{2} \| w \|^2 - \sum_{i=1}^n \lambda_i y_i w^T x_i  + \sum_{i=1}^n \lambda_i \right]
&= \max_{\lambda} \left[ \frac{1}{2} \| \sum_{i=1}^n \lambda_i y_i x_i \|^2 - \sum_{i=1}^n \lambda_i y_i \sum_{j=1}^n \lambda_j y_j x_j^T x_i  + \sum_{i=1}^n \lambda_i \right] \\
&= \max_{\lambda} \left[ \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j - \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j  + \sum_{i=1}^n \lambda_i \right] \\
&= \max_{\lambda} \left[ \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j \right]
\end{aligned}
$$

ì‹ì„ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

$$
\begin{aligned}
\max_{\lambda} \left[ \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j \right] \\
\text{where} \quad \lambda_i \ge 0 \quad \text{and} \quad \sum_{i=1}^n \lambda_i y_i = 0
\end{aligned}
$$

ìœ„ì˜ ìµœì í™” ë¬¸ì œì˜ è§£ëŠ” \<QP; Quadratic Programming)\>ë¡œ ì–»ì„ ìˆ˜ ìˆë‹¤ë©°, ê·¸ë•Œì˜ è§£ $\lambda^{*}$ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

$$
\begin{aligned}
\lambda^{*} = \underset{\lambda}{\text{argmax}} \; \left[ \sum_{i=1}^n \lambda_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^T x_j \right] \\
\text{where} \quad \lambda_i \ge 0 \quad \text{and} \quad \sum_{i=1}^n \lambda_i y_i = 0
\end{aligned}
$$

ì´ì œ, solution $\lambda^{*}$ëŒ€ì…í•˜ë©´ $w$, $b$ì— ëŒ€í•œ è§£ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

$$
w^{*} = \sum_{i=1}^n \lambda^{*}_i y_i x_i
$$

ì´ë•Œ $\lambda^{*}_i$ëŠ” 0 ë˜ëŠ” ì–‘ìˆ˜ì˜ ê°’ì„ ê°–ëŠ”ë°,

- If $\lambda^{*}_i = 0$, then $x_i$ëŠ” hyper-planeì„ ì •ì˜í•˜ëŠ”ë° ê¸°ì—¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
- If $\lambda^{*}_i > 0$, then $x_i$ëŠ” hyper-planeì„ ì •ì˜í•˜ëŠ”ë° ê¸°ì—¬í•˜ê³ , ì´ê²ƒì„ "**support vector**"ë¼ê³  ë¶€ë¥¸ë‹¤!

$b^{*}$ëŠ” $w^T x_{+} + b = 1$ì˜ ì‹ì„ í†µí•´ ìœ ë„í•˜ë©´ ëœë‹¤. ë”°ë¡œ ì‹ì„ ì œì‹œí•˜ì§€ëŠ” ì•Šê² ë‹¤.

<hr/>

### Soft-margin SVM

ë§Œì•½ ë°ì´í„°ì…‹ì´ linearly separable í•˜ì§€ ì•Šë‹¤ë©´, ìœ„ì˜ \<SVM\>ì˜ è§£ë¥¼ êµ¬í•  ìˆ˜ ì—†ë‹¤! ğŸ¤¯ ì´ëŸ° ê²½ìš°ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ \<slack variable\> $\xi_i$ë¥¼ ë„ì…í•œë‹¤! ê·¸ ê²°ê³¼, \<SVM\>ì— ëŒ€í•œ ì‹ì€ ì•„ë˜ì™€ ê°™ì€ ìµœì í™” ë¬¸ì œê°€ ëœë‹¤.

$$
\begin{aligned}
\min_{w, b, \xi} \frac{1}{2} \| w \|^2 &+ C \sum_{i=1}^n \xi_i\\
\text{subject to} &\quad  y_i (w^T x_i + b) \ge 1 - \xi_i \;\; \forall i,
\quad \text{and} \quad \xi_i \ge 0
\end{aligned}
$$

ì´ê²ƒì€ support vectorê°€ ë§Œë“œëŠ” margin ì˜ì—­ë³´ë‹¤ ë” ì•ˆìª½ì— ëª‡ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ ì¡´ì¬í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ ì¤€ë‹¤!

$$
y_i (w^T x_i + b) \ge 1 - \xi_i
$$

ì‰½ê²Œ ìƒê°í•´ ë°ì´í„°ì…‹ì„ non-separable í•˜ê²Œ ë§Œë“œëŠ” ë°ì´í„°í¬ì¸íŠ¸ì— ëŒ€í•´ì„  $\xi_i$ê°€ ì–‘ìˆ˜ì˜ ê°’ì„ ê°€ì ¸ ê·¸ë“¤ì˜ margin ê°’ì´ ì¡°ê¸ˆ ì‘ì•„ì ¸ë„ í—ˆìš©í•œë‹¤ê³  ì´í•´í•´ë„ ë  ê²ƒ ê°™ë‹¤.

<hr/>

### Non-Linear SVM



<hr/>


[^1]: ë¬¼ë¡  ì–´ëŠ í•œìª½ì˜ support vectorê°€ ë” ì§§ì„ ìˆ˜ë„ ìˆê² ì§€ë§Œ, ê·¸ê²ƒì€ SVMì˜ ì·¨ì§€ì— ì–´ê¸‹ë‚˜ë¯€ë¡œ ê¸°ê°í•œë‹¤.

