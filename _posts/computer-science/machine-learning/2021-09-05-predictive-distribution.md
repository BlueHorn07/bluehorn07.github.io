---
title: "Predictive Distribution"
toc: true
toc_sticky: true
categories: ["Machine Learning"]
modified_date: 2021.09.20
readtime: 30 Minutes
---



"Machine Learning"ì„ ê³µë¶€í•˜ë©´ì„œ ê°œì¸ì ì¸ ìš©ë„ë¡œ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<div class="proof" markdown="1">

**ê¸°íš ì‹œë¦¬ì¦ˆ: Bayesian Regression**

1. [MLE vs. MAP]({{"/2021/09/05/MLE-vs-MAP" | relative_url}})
2. [Predictive Distribution]({{"/2021/09/05/predictive-distribution" | relative_url}}) ğŸ‘€
3. [Bayesian Regression]({{"/2021/09/06/bayesian-regression" | relative_url}})

</div>

<hr/>

## Bayesian Approach

ì´ë²ˆ í¬ìŠ¤íŠ¸ë¶€í„° ë³¸ê²©ì ìœ¼ë¡œ Bayesian Approachì— ëŒ€í•´ íƒêµ¬í•œë‹¤. ë¨¼ì € Bayesianì˜ ê´€ì ì—ì„œëŠ” í™•ë¥ (probability)ì„ <span class="half_HL">"ê°€ì„¤ì— ëŒ€í•œ ë¯¿ìŒì˜ ì •ë„"</span>ë¡œì„œ ì´í•´í•œë‹¤. ê·¸ë˜ì„œ ì‚¬ì „ ë¯¿ìŒì„ ê°€ì§€ê³  ê°€ì„¤ì„ ì‚´í´ë³´ê³ , ì´í›„ì— ë°ì´í„°ë¥¼ ê´€ì¸¡í–ˆë‹¤ë©´ ê·¸ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìƒˆë¡­ê²Œ ë¯¿ìŒì„ ê°±ì‹ í•´ ì‚¬í›„ ë¯¿ìŒì„ ì–»ëŠ”ë‹¤. ì´ëŸ° ìˆ˜ì§‘-ê°±ì‹ ì˜ ê³¼ì •ì„ ë°ì´í„°ê°€ ë°œìƒí•  ë•Œë§ˆë‹¤ ê³„ì† ë°˜ë³µí•œë‹¤.

ê¸°ì–µí•  ì ì€ Bayesian ApproachëŠ” í•­ìƒ 'ë¶ˆí™•ì‹¤ì„±(uncertainty)'ì— ëŒ€í•´ ì–˜ê¸°í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ê³ ì „ì ì¸ í™•ë¥ ë¡ ì´ **Point Estimation**ìœ¼ë¡œ unbiased estimator ë˜ëŠ” the most efficient estimator of $\theta$[^1]ë¥¼ êµ¬í•˜ê±°ë‚˜ ë˜ëŠ” **Interval Estimation**ìœ¼ë¡œ confidence levelì„ êµ¬í•˜ëŠ” ë“±ì˜ ì¶”ì •ì„ ìˆ˜í–‰í•˜ì§€ë§Œ, Bayesian ApproachëŠ” parameter $\theta$ì— ëŒ€í•œ <b><span style="color: red">'í™•ë¥  ë¶„í¬'</span></b>ë¥¼ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ê·¸ë˜ì„œ Point Estimationì—ì„œ ì²˜ëŸ¼ parameterì˜ ê°’ì„ $\theta = \theta_0$ë¡œ íŠ¹ì •í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ "$\mu = 4$, $\sigma^2 = 1$ì¸ ì •ê·œë¶„í¬ë¡œ parameterê°€ ë¶„í¬ë˜ì–´ ìˆë‹¤"ë¼ê³  ë§í•œë‹¤.

<span class="half_HL">Bayesian Approachì—ì„œëŠ” ê´€ì¸¡ ë°ì´í„°ê°€ ì¶”ê°€ë¨ì— ë”°ë¼ parameterì˜ distributionì„ ê³„ì† ê°±ì‹ í•œë‹¤.</span> ì´ëŠ” parameterì˜ prior distributionì„ ìƒˆë¡­ê²Œ ê´€ì¸¡ëœ ë°ì´í„°ë¡œ ê°±ì‹ í•´ posterior distributionì„ ì–»ëŠ” ì…ˆì´ë‹¤. [ì´ ì•„í‹°í´](https://coffeewhale.com/bayesian/linear/regression/2019/10/19/bayesian-lr/)ì—ì„œëŠ” ì´ê²ƒì„ "ë°ì´í„°ê°€ í™•ë¥  ë¶„í¬ë¥¼ ì¡ì•„ë‹¹ê¸°ëŠ” ìì„ê³¼ ê°™ë‹¤"ê³  í‘œí˜„í•˜ëŠ”ë°, í‘œí˜„ì´ ê·¸ëŸ´ì‹¸ í•˜ë‹¤ ğŸ˜² ìì„¸í•œ ë‚´ìš©ì€ í•´ë‹¹ ì•„í‹°í´ì˜ [ìš” ë¶€ë¶„](https://coffeewhale.com/bayesian/linear/regression/2019/10/19/bayesian-lr/#:~:text=%EC%A0%80%EB%8A%94%20%EC%9D%B4%EA%B2%83%EC%9D%84%20%EB%8B%A4%EC%9D%8C%EA%B3%BC%20%EA%B0%99%EC%9D%B4%20%ED%91%9C%ED%98%84%ED%95%98%EA%B8%B8%20%EC%A2%8B%EC%95%84%ED%95%A9%EB%8B%88%EB%8B%A4.)ì„ ì ê¹ ì½ì–´ë³´ê³  ì˜¤ëŠ” ê±¸ ì¶”ì²œí•œë‹¤. ê¸€ì„ í†µí•´ ë°ì´í„°ê°€ posterior distributionì„ ì–´ë–»ê²Œ ê°±ì‹ í•˜ëŠ”ì§€ ê·¸ë¦¬ê³  prior distributionì„ ì˜ ì¡ëŠ”ê²Œ ì¤‘ìš”í•œ ì´ìœ ë¥¼ ê¹¨ë‹¬ì„ ìˆ˜ ìˆë‹¤ ğŸ‘

<div class="img-wrapper">
  <img src="{{ "/images/computer-science/machine-learning/bayesian-approach-1.png" | relative_url }}" width="100%">
</div>

ê¸°ì¡´ì˜ ê³ ì „ì ì¸ ë°©ë²•ì€ Point Estimatorë‚˜ confidence intervalë¥¼ ìœ ë„í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ Bayesian Approachì—ì„œëŠ” ê·¸ëŸ° ê²ƒë“¤ì´ ì „í˜€ ì—†ìœ¼ë©°ğŸ‘‹ ë‹¨ì§€ parameterì— ëŒ€í•œ **posterior distribution**ì„ ì´ìš©í•´ ìƒˆë¡œìš´ ë°ì´í„° $x^{*}$ë¥¼ ì˜ˆì¸¡í•  ë¿ì´ë‹¤. ê·¸ë¦¬ê³  ì´ ê³¼ì •ì—ì„œ ë“±ì¥í•˜ëŠ” ê²ƒì´ ë°”ë¡œ \<**Predictive Distribution**; ì˜ˆì¸¡ ë¶„í¬\>ì´ë‹¤!

<hr/>

## Parameter Posterior

ì•ì˜ ë¬¸ë‹¨ì—ì„œ Bayesian Approachê°€ ê´€ì¸¡ ë°ì´í„°ë¡œ parameterì˜ distributionì„ ê°±ì‹ í•œë‹¤ê³  ê¸°ìˆ í–ˆë‹¤. ì´ê²ƒì„ ì¢€ë” ì‚´í´ë³´ì! ì œì¼ ë¨¼ì € parameter $\theta$ì— ëŒ€í•œ prior distributionì„ ê°€ì •í•œë‹¤. ì´ê²ƒì„ \<prior distribution of parameter\> ë˜ëŠ” \<parameter prior\>ë¼ê³  í•˜ë©°, ì—¬ê¸°ì„œëŠ” ì•„ë˜ì™€ ê°™ì€ ì •ê·œ ë¶„í¬ë¥¼ ê°€ì •í•˜ê² ë‹¤.

$$
\theta \sim N(0, \tau^2 I)
$$

ì´ì œ ê´€ì¸¡ëœ ë°ì´í„° $X = \\{ x^{(1)}, \dots, x^{(m)} \\}$ë¥¼ ì´ìš©í•´ \<parameter prior\> $p(\theta)$ë¥¼ ê°±ì‹ í•´ë³´ì. \<parameter posterior\> $p(\theta \mid X)$ëŠ” Bayes Ruleì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì´ ìœ ë„í•  ìˆ˜ ìˆë‹¤.

$$
\begin{aligned}
p(\theta \mid X)
&= \frac{p(X \mid \theta) p(\theta)}{p(X)} = \frac{p(X \mid \theta) p(\theta)}{\int_{\theta'} p(X \mid \theta') p(\theta') d\theta'} \\
&= \frac{p(\theta) \prod^m_{i=1} p(x^{(i)} \mid \theta)}{\int_{\theta'} p(\theta') \prod^m_{i=1} p(x^{(i)} \mid \theta') d\theta'}
\end{aligned}
$$

ì´ë•Œ, likelihoodì˜ $p(x^{(i)} \mid \theta)$ëŠ” $\theta$ë¡œ parametizedëœ í™•ë¥  ë³€ìˆ˜ $X$ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¡œ ì´í•­ ë¶„í¬, ì •ê·œ ë¶„í¬, í¬ì•„ì†¡ ë¶„í¬ ë“±ë“±ì´ ê°€ëŠ¥í•˜ë‹¤. likelihoodëŠ” ë°ì´í„°ê°€ parameter $\theta$ì— ì˜í•´ ì–´ë–»ê²Œ parameterized ë˜ì–´ ìˆì„ ê²ƒì´ë¼ê³  **ê°€ì •**í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ê°±ì‹ í•˜ëŠ” ëŒ€ìƒì´ ì•„ë‹ˆë‹¤! ğŸ™Œ

**<u>ì´í•­ë¶„í¬</u>**

$$
p(x^{(i)} \mid \theta) = \frac{n!}{x!(n-x)!} \theta^x (1 - \theta)^{(n-x)}
$$

**<u>1D-ì •ê·œë¶„í¬</u>**

$$
p(x^{(i)} \mid \theta) = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( - \frac{(x^{(i)} - \theta)^2}{2\sigma^2}\right)
$$

**<u>2D-ì •ê·œë¶„í¬</u>** ($x^{(i)} \in \mathbb{R}^2$, also $\theta \in \mathbb{R}^2$)

$$
p(x^{(i)} \mid \theta) = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( - \frac{(x^{(i)} - \theta)^2}{2\sigma^2}\right)
$$

ë“±ë“±ë“±!!

<div class="example" markdown="1">

<span class="statement-title">Example.</span> Parameter Posterior<br>

ë™ì „ì„ ë˜ì¡Œì„ ë•Œ, ì•ë©´ì´ ë‚˜ì˜¬ í™•ë¥ ì´ ê· ì¼ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤. ë™ì „ì„ ë˜ì¡Œë”ë‹ˆ ì•ë©´ì´ ë‚˜ì™”ì„ ë•Œ, parameter posterë¥¼ êµ¬í•˜ë¼.

<div class="proof" markdown="1">

<details markdown="1">
<summary>Solution</summary>

"ì•ë©´ì´ ë‚˜ì˜¬ **í™•ë¥ **ì´ ê· ì¼ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤." <br/>
â†’ $p(\theta) = I_{(0 \le \theta \le 1)}$ (parameter prior)

"ë™ì „ì„ ë˜ì§„ë‹¤."<br/>
â†’ $p(x \mid \theta) = \theta^x (1 - \theta)^{(1-x)}$ (likelihood)

"ë™ì „ì„ ë˜ì¡Œë”ë‹ˆ ì•ë©´ì´ ë‚˜ì™”ì„ ë•Œ"<br/>
â†’ $x_1 = 1$

$$
\begin{aligned}
p(\theta \mid x_1 = 1)
&= \frac{p(x_1 = 1 \mid \theta) p(\theta)}{p(x_1 = 1)}  \\
&= \frac{\theta \cdot p(\theta)}{1/2} \\
&= 2 \theta \cdot p(\theta) = 2\theta
\end{aligned}
$$

ê°±ì‹ ëœ parameter posteriorì—ì„œëŠ” ì•ë©´ì´ ë§ì´ ë‚˜ì˜¬ ê±°ë¼ëŠ” í™•ë¥ (=ë¯¿ìŒ)ì´ ë°˜ì˜ë˜ì—ˆë‹¤.

$\blacksquare$

</details>

</div>

</div>

<hr/>

## Predictive Distribution

\<**Predictive Distribution**; ì˜ˆì¸¡ ë¶„í¬\>ëŠ” unobserved data $x^{\*} \in X^{\*}$ì— ëŒ€í•œ predictionì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ìœ ë„í•˜ëŠ” ë¶„í¬ì´ë‹¤. ê·¸ë˜ì„œ ì´ë¦„ì— "predictive"ë¼ëŠ” ì´ë¦„ì´ ë¶™ì—ˆë‹¤ê³  í•  ìˆ˜ ìˆë‹¤. ~~ë‡Œí”¼ì…œì…ë‹ˆë‹¤~~ \<Predictive Distribution\>ì€ parameter priorë¡œ ìœ ë„í•˜ëŠ”ì§€, observed data $X$ê°€ ë°˜ì˜ëœ parameter posteriorë¡œ ìœ ë„í•˜ëŠ”ì§€ì— ë”°ë¼ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤.

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Prior Predictive Distribution<br>

Let $X = \\{ x^{(1)}, \dots, x^{(m)} \\}$ be a set of observed data, $X^{\*}$ be a set of unobsersed data, and $x^{\*} \in X^{\*}$.

Then, the \<prior predictive distribution\> is

$$
p(x^{*}) = \int p(x^{*}, \theta) d\theta = \int p(x^{*} \mid \theta) p(\theta) d\theta
$$

ì¦‰, likelihood $p(x \mid \theta)$ë¥¼ parameter prior $p(\theta)$ì˜ í™•ë¥  ë¶„í¬ë¥¼ ê³ ë ¤í•´ ì ë¶„í•œ ê²ƒì´ \<**prior predictive distribution**\>ì´ë‹¤.

</div>

ê·¸ëŸ¬ë‚˜ \<prior predictive distribution\>ì€ observed data $X$ë¥¼ ì „í˜€ ì“°ê³  ìˆì§€ ì•Šë‹¤. observed dataë¥¼ ì œëŒ€ë¡œ í™œìš©í•˜ë ¤ë©´ parameter posterior $p(\theta \mid X)$ë¡œ ìœ ë„í•œ \<**posterior predictive distribution**\>ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤!

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Posterior Predictive Distribution<br>

$$
p(x^{*} \mid X) = \int p(x^{*}, \theta \mid X) d\theta = \int p(x^{*} \mid \theta, X) p(\theta \mid X) d\theta
$$

ë³´í†µ $x^{\*}$ì™€ $X$ë¥¼ ë…ë¦½ì´ë¼ê³  ê°€ì •í•˜ê¸° ë•Œë¬¸ì— ë˜ëŠ” iidë¥¼ ê°€ì •í•˜ë¯€ë¡œ,

$$
p(x^{*} \mid X) = \int p(x^{*} \mid \theta, X) p(\theta \mid X) d\theta = \int p(x^{*} \mid \theta) p(\theta \mid X) d\theta
$$

</div>

\<prior predictive distribution\>ê³¼ ë¹„êµí–ˆì„ ë•Œ ë‹¬ë¼ì§„ ì ì€ ì ë¶„ ë‚´ë¶€ì˜ í•¨ìˆ˜ê°€ parameter prior $p(\theta)$ì—ì„œ parameter posterior $p(\theta \mid X)$ë¡œ ë°”ë€Œì—ˆë‹¤ëŠ” ì ì´ë‹¤! \<posterior predictive distribution\>ì€ ê´€ì¸¡ëœ ë°ì´í„°ë¡œ ê°±ì‹ ëœ \<parameter posterior\>ë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ì‹¤ì œ ëª¨ìˆ˜(parameter)ì™€ ê·¼ì ‘í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ëŠ” ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡(prediction)í–ˆë‹¤ê³  ê¸°ëŒ€í•˜ê²Œ ëœë‹¤.

[ì´ ì•„í‹°í´](https://rooney-song.tistory.com/9?category=935544/#:~:text=ë¬¸ì œ)ì˜ í•´ë‹¹ ë¶€ë¶„ì—ì„œ predictive distributionì„ ìœ ë„í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì œë¥¼ í’€ì–´ë³¼ ìˆ˜ ìˆë‹¤. ë¬¸ì œê°€ ì¢‹ìœ¼ë‹ˆ í•œë²ˆì¯¤ í’€ì–´ë³´ë„ë¡ í•˜ì ğŸ‘€ ì°¸ê³ ë¡œ ì²«ë²ˆì§¸ ì˜ˆì œì—ì„œ Gamma function $\Gamma$ë¥¼ ì¨ì„œ ì ë¶„í•˜ëŠ” ë¶€ë¶„ì€ [Beta Distribution]({{"/2021/04/06/chi-and-beta-and-lognormal-distribution#beta-distribution" | relative_url}})ì— ëŒ€í•œ ì ë¶„ì´ë‹¤.

<hr/>

ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” \<Predictive Distribution\>ì„ ì´ìš©í•´ Regression Problemì„ ë‹¤ë£¬ë‹¤. ì´ê²ƒì„ \<Bayesian Linear Regression\>ì´ë¼ê³  í•˜ë©° ì´ë²ˆ í¬ìŠ¤íŠ¸ë¥¼ ì˜ ì´í•´í–ˆë‹¤ë©´ ë‹¤ìŒ í¬ìŠ¤íŠ¸ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤ ğŸ˜

ğŸ‘‰ [Bayesian Regression]({{"/2021/09/06/bayesian-regression" | relative_url}})

<hr/>

### reference

- [[ë²ˆì—­] ì„ í˜• íšŒê·€ ëª¨ë¸ Bayesians vs Frequentists](https://coffeewhale.com/bayesian/linear/regression/2019/10/19/bayesian-lr)
- [Prior & Posterior Predictive Distributions](https://donghwa-kim.github.io/Pred_-baye)
- [ì‚¬ì „ì˜ˆì¸¡ë¶„í¬ì™€ ì‚¬í›„ì˜ˆì¸¡ë¶„í¬(Prior and posterior predictive distribution)](https://rooney-song.tistory.com/9?category=935544)
- [[Bayesian DL] 1. Properties of Gaussian Distribution and Prior(Posterior) Predictive Distribution](https://medium.com/jun-devpblog/bayesian-dl-1-properties-of-gaussian-distribution-and-prior-posterior-predictive-distribution-b02529b894a8)

<hr/>

[^1]: unbiased estimaor with the smallest variance