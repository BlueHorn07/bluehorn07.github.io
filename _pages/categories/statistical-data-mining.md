---
title: "Statistical Data Mining"
permalink: /categories/statistical-data-mining
toc: true
toc_sticky: true
---

<br/>

2021-1í•™ê¸°ì— ìˆ˜ê°•í•œ POSTECH ì±„ë¯¼ìš° êµìˆ˜ë‹˜ì˜ "**í†µê³„ì  ë°ì´í„° ë§ˆì´ë‹(IMEN472)**" ìˆ˜ì—…ì—ì„œ ë°°ìš´ ê²ƒê³¼ ê³µë¶€í•œ ê²ƒì„ ì •ë¦¬í•œ ì§€í‚¬ ë¸”ë¡œê·¸ì…ë‹ˆë‹¤. ê°œì¸ì ìœ¼ë¡œ ë³¸ì¸ì´ ì²˜ìŒ ë„ì „í•´ë³´ëŠ” ë¶„ì•¼ê³  ì‘ìš© ìˆ˜í•™ì˜ ìˆ˜ë§ì€ í…Œí¬ë‹‰ë“¤ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ìˆ˜ì—…ì„ ë”°ë¼ê°€ëŠ”ê²Œ ì‰½ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤ë§Œ, ë³¸ ìˆ˜ì—…ì„ í†µí•´ì„œ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì— ëŒ€í•œ í”„ë¡ í‹°ì–´ë¥¼ ë§›ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ğŸ¤¯

## ì°¸ê³  êµì¬
- [ã€The Elements of Statistical Learningã€](https://web.stanford.edu/~hastie/ElemStatLearn/) Trevor Hastie Â· Robert Tibshirani Â· Jerome Friedman, 2nd ed.
- [ã€An Introduction to Statistical Learningã€](https://www.statlearning.com/) Gareth James Â· Daniela Witten Â· Trevor Hastie Â· Robert Tibshirani, 1st ed.
- [CS229: Machine Learning](http://cs229.stanford.edu/syllabus-autumn2018), Andrew Ng, Stanford Univ. [^1]

<hr/>

## Supplementary

ì•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” "í†µë°ë§ˆ"ì˜ ì‹¤ì „ì„ ë§ˆì£¼í•˜ê¸° ì „ì— "**ë°˜ë“œì‹œ**" ì•Œì•„ì•¼ í•˜ëŠ” ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ì—¬ê¸°ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ë‚´ìš©ê³¼ ìˆ˜í•™ì  í‘œí˜„ì— ì¶©ë¶„íˆ ìµìˆ™í•´ì ¸ì•¼ í•©ë‹ˆë‹¤.

<details markdown="1" class="statement">
<summary>í¼ì³ë³´ê¸°</summary>

### Linear Algebra

- [Basic Linear Algebra]({{"/2021/03/07/supp-1-linear-algebra-1" | relative_url}})
  - Column space & Row space & Null space
  - Fundamental Theorem of Linear Algebra
- [Eigen value & Eigen vector]({{"/2021/03/08/supp-1-linear-algebra-2#eigen-value--eigen-vector" | relative_url}})
- [Vector Calculus & Matrix Calculus]({{"/2021/03/08/supp-1-linear-algebra-2#matrix-calculus" | relative_url}})
- [Spectral Decomposition & Singular Value Decomposition]({{"/2021/03/14/supp-1-linear-algebra-3" | relative_url}})
- [Nonnegative Definite & Positive Definite Matrix]({{"/2021/03/27/supp-1-linear-algebra-4" | relative_url}})
- [Orthogonal Projection]({{"/2021/03/27/supp-1-linear-algebra-4#orthogonal-projection" | relative_url}})

### Multivariate Normal Distribution

### Conditional Expectation

</details>

<hr/>

## [Introduction]({{"/2021/02/26/overview-of-supervised-learning" | relative_url}})

- Introduction to Regression & Classification
  - Least Squared Method
  - Nearest Neighbor Method
- Curse of dimentionality

<hr/>

## Linear Methods for Regression

- [Feature Selection]({{"/2021/05/16/feature-selection-techniques" | relative_url}})
  - Best Subset Selection
  - Forward Stepwise Selection
  - Backward Stepwise Selection
  - Mallow's $C_p$
  - AIC & BIC
  - Instability of Variable Selection

- Shrinkage Method

- Lasso Regression
- Ridge Regression

<hr/>

## Non-parametric Method

- [Non-parametric Linear Regression]({{"/2021/04/18/regression-spline" | relative_url}})
  - Polynomial Regression
    - Local Polynomical Regression
  - [Regression Spline]({{"/2021/04/18/regression-spline#regression-spine" | relative_url}}) ğŸ”¥
  - Natural Cubic Spline
    - power basis function
  - [Smoothing Splines]({{"/2021/04/18/regression-spline#smoothing-splines" | relative_url}})
    - knot selection
  - [Non-parametric Logistic Regression]({{"/2021/04/19/splines-method-2#non-parameteric-logistic-regression" | relative_url}})
  - [Multi-dimensional Splines]({{"/2021/04/19/splines-method-2#multi-dimensional-splines" | relative_url}})

- [KNN Method]({{"/2021/05/16/KNN-and-kernel-method" | relative_url}})
  - [kernel method]({{"/2021/05/16/KNN-and-kernel-method#kernel-method" | relative_url}})
- [Nadaraya-Watson Estimator]({{"/2021/05/16/KNN-and-kernel-method#nadaraya-watson-estimator" | relative_url}})

- [Additive Model]({{"/2021/05/17/additive-model-and-gam#additive-model" | relative_url}})
  - Backfitting Algorithm
- [GAM; Generalized Additive Models]({{"/2021/05/17/additive-model-and-gam#gam-generalized-additive-model" | relative_url}}) ğŸ”¥
- [MARS; Multivariate Adaptive Regression Spline]({{"/2021/05/22/MARS" | relative_url}}) ğŸ”¥


<hr/>

## Boosting

- [Introduction to Boosting]({{"/2021/05/09/introduction-to-boosting" | relative_url}})
- [AdaBoost]({{"/2021/05/10/AdaBoost" | relative_url}})
- Gradient Boosting
- XGBoost

<hr/>

## Random Forest

<hr/>

## Appendix

- [ë‚´ê°€ ë³´ë ¤ê³  ë§Œë“  'í†µê³„ ë¶„ì„' Cheat Sheet]({{"/2021/05/17/statistical-analysis-cheat-sheet-for-me" | relative_url}})



<hr/>

[^1]: ìˆ˜ì—…ì˜ ì¼ë¶€ í† í”½ì—ì„œ CS229ì—ì„œ ë°°ìš´ ë¶€ë¶„ì´ ì¢…ì¢… ë“±ì¥í–ˆìŠµë‹ˆë‹¤. CS229ì—ì„œ í†µê³„ì  ì ‘ê·¼ì„ í†µí•´ ê³ ì „ì ì¸ ë¨¸ì‹  ëŸ¬ë‹ì„ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— ë‘ ê³¼ëª©ì„ ê³µë¶€í•˜ëŠ” ë°ì— ì–‘ë°©í–¥ìœ¼ë¡œ ë„ì›€ì„ ë§ì´ ë°›ì•˜ìŠµë‹ˆë‹¤ ğŸ˜Š


